<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>vtreat cross frames • vtreat</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="vtreat cross frames">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">vtreat</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.3.6</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/vtreat.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/MultiClassVtreat.html">Multi Class vtreat</a>
    </li>
    <li>
      <a href="../articles/SavingTreamentPlans.html">Saving Treatment Plans</a>
    </li>
    <li>
      <a href="../articles/VariableImportance.html">vtreat Variable Importance</a>
    </li>
    <li>
      <a href="../articles/vtreatCrossFrames.html">vtreat cross frames</a>
    </li>
    <li>
      <a href="../articles/vtreatGrouping.html">Grouping Example</a>
    </li>
    <li>
      <a href="../articles/vtreatOverfit.html">vtreat overfit</a>
    </li>
    <li>
      <a href="../articles/vtreatRareLevels.html">vtreat Rare Levels</a>
    </li>
    <li>
      <a href="../articles/vtreatScaleMode.html">vtreat scale mode</a>
    </li>
    <li>
      <a href="../articles/vtreatSignificance.html">vtreat significance</a>
    </li>
    <li>
      <a href="../articles/vtreatSplitting.html">vtreat splitting</a>
    </li>
    <li>
      <a href="../articles/vtreatVariableTypes.html">Variable Types</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="http://www.win-vector.com/">Sponsor: Win-Vector LLC</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>vtreat cross frames</h1>
                        <h4 class="author">John Mount, Nina Zumel</h4>
            
            <h4 class="date">2019-02-09</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/WinVector/vtreat/blob/master/vignettes/vtreatCrossFrames.Rmd"><code>vignettes/vtreatCrossFrames.Rmd</code></a></small>
      <div class="hidden name"><code>vtreatCrossFrames.Rmd</code></div>

    </div>

    
    
<p>Example demonstrating “cross validated training frames” (or “cross frames”) in vtreat.</p>
<p>Consider the following data frame. The outcome only depends on the “good” variables, not on the (high degree of freedom) “bad” variables. Modeling such a data set runs a high risk of over-fit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Random">set.seed</a></span>(<span class="dv">22626</span>)

mkData &lt;-<span class="st"> </span><span class="cf">function</span>(n) {
  d &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/data.frame">data.frame</a></span>(<span class="dt">xBad1=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sample">sample</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(<span class="st">'level'</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,<span class="dt">sep=</span><span class="st">''</span>),n,<span class="dt">replace=</span><span class="ot">TRUE</span>),
                  <span class="dt">xBad2=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sample">sample</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(<span class="st">'level'</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,<span class="dt">sep=</span><span class="st">''</span>),n,<span class="dt">replace=</span><span class="ot">TRUE</span>),
                  <span class="dt">xBad3=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sample">sample</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(<span class="st">'level'</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,<span class="dt">sep=</span><span class="st">''</span>),n,<span class="dt">replace=</span><span class="ot">TRUE</span>),
                  <span class="dt">xGood1=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(n),
                  <span class="dt">xGood2=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(n))
  
  <span class="co"># outcome only depends on "good" variables</span>
  d<span class="op">$</span>y &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(d))<span class="op">+</span><span class="fl">0.2</span><span class="op">*</span>d<span class="op">$</span>xGood1 <span class="op">+</span><span class="st"> </span><span class="fl">0.3</span><span class="op">*</span>d<span class="op">$</span>xGood2<span class="op">&gt;</span><span class="fl">0.5</span>
  <span class="co"># the random group used for splitting the data set, not a variable.</span>
  d<span class="op">$</span>rgroup &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sample">sample</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"cal"</span>,<span class="st">"train"</span>,<span class="st">"test"</span>),<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(d),<span class="dt">replace=</span><span class="ot">TRUE</span>)  
  d
}

d &lt;-<span class="st"> </span><span class="kw">mkData</span>(<span class="dv">2000</span>)

<span class="co"># devtools::install_github("WinVector/WVPlots")</span>
<span class="co"># library('WVPlots')</span>
plotRes &lt;-<span class="st"> </span><span class="cf">function</span>(d,predName,yName,title) {
  <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(title)
  tab &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/table">table</a></span>(<span class="dt">truth=</span>d[[yName]],<span class="dt">pred=</span>d[[predName]]<span class="op">&gt;</span><span class="fl">0.5</span>)
  <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(tab)
  diag &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sum">sum</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/lapply">vapply</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/seq">seq_len</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Extremes">min</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/dim">dim</a></span>(tab))),
                     <span class="cf">function</span>(i) tab[i,i],<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/numeric">numeric</a></span>(<span class="dv">1</span>)))
  acc &lt;-<span class="st"> </span>diag<span class="op">/</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sum">sum</a></span>(tab)
<span class="co">#  if(requireNamespace("WVPlots",quietly=TRUE)) {</span>
<span class="co">#     print(WVPlots::ROCPlot(d,predName,yName,title))</span>
<span class="co">#  }</span>
  <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(<span class="st">'accuracy'</span>,acc))
}</code></pre></div>
<div id="the-wrong-way" class="section level2">
<h2 class="hasAnchor">
<a href="#the-wrong-way" class="anchor"></a>The Wrong Way</h2>
<p>Bad practice: use the same set of data to prepare variable encoding and train a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">!=</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
dTest &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
treatments &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/designTreatmentsC">designTreatmentsC</a></span>(dTrain,<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'xBad1'</span>,<span class="st">'xBad2'</span>,<span class="st">'xBad3'</span>,<span class="st">'xGood1'</span>,<span class="st">'xGood2'</span>),
                                        <span class="st">'y'</span>,<span class="ot">TRUE</span>,
  <span class="dt">rareCount=</span><span class="dv">0</span> <span class="co"># Note: usually want rareCount&gt;0, setting to zero to illustrate problem</span>
)</code></pre></div>
<pre><code>## [1] "vtreat 1.3.6 inspecting inputs Sat Feb  9 10:25:58 2019"
## [1] "designing treatments Sat Feb  9 10:25:58 2019"
## [1] " have initial level statistics Sat Feb  9 10:25:58 2019"
## [1] " scoring treatments Sat Feb  9 10:25:58 2019"
## [1] "have treatment plan Sat Feb  9 10:25:58 2019"
## [1] "rescoring complex variables Sat Feb  9 10:25:58 2019"
## [1] "done rescoring complex variables Sat Feb  9 10:25:59 2019"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrainTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTrain,
  <span class="dt">pruneSig=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>() <span class="co"># Note: usually want pruneSig to be a small fraction, setting to null to illustrate problems</span>
)

f &lt;-<span class="st"> </span>wrapr<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/wrapr/topics/mk_formula">mk_formula</a></span>(<span class="st">"y"</span>, treatments<span class="op">$</span>scoreFrame<span class="op">$</span>varName)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(f)</code></pre></div>
<pre><code>## y ~ xBad1_catP + xBad1_catB + xBad2_catP + xBad2_catB + xBad3_catP + 
##     xBad3_catB + xGood1 + xGood2
## &lt;environment: base&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/glm">glm</a></span>(f,
          <span class="dt">data=</span>dTrainTreated,<span class="dt">family=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/family">binomial</a></span>(<span class="dt">link=</span><span class="st">'logit'</span>))</code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(m1))  <span class="co"># notice low residual deviance</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = f, family = binomial(link = "logit"), data = dTrainTreated)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.40374  -0.00038  -0.00001   0.00002   2.47736  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)    2.0555     1.6233   1.266  0.20543   
## xBad1_catP  -134.1696   398.7304  -0.336  0.73650   
## xBad1_catB     0.9509     0.3034   3.134  0.00173 **
## xBad2_catP  -310.2310   386.8597  -0.802  0.42260   
## xBad2_catB     0.9663     0.3178   3.041  0.00236 **
## xBad3_catP  -635.5629   341.6498  -1.860  0.06285 . 
## xBad3_catB     1.2120     0.4255   2.849  0.00439 **
## xGood1         0.8381     0.2702   3.102  0.00192 **
## xGood2         0.9379     0.3017   3.109  0.00188 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1724.55  on 1331  degrees of freedom
## Residual deviance:  110.93  on 1323  degrees of freedom
## AIC: 128.93
## 
## Number of Fisher Scoring iterations: 12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(m1,<span class="dt">newdata=</span>dTrainTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTrain,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on train'</span>)</code></pre></div>
<pre><code>## [1] "model1 on train"
##        pred
## truth   FALSE TRUE
##   FALSE   849   17
##   TRUE      7  459
## [1] "accuracy 0.981981981981982"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTestTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTest,<span class="dt">pruneSig=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>())
dTest<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(m1,<span class="dt">newdata=</span>dTestTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTest,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on test'</span>)</code></pre></div>
<pre><code>## [1] "model1 on test"
##        pred
## truth   FALSE TRUE
##   FALSE   281  193
##   TRUE    119   75
## [1] "accuracy 0.532934131736527"</code></pre>
<p>Notice above that we see a training accuracy of 98% and a test accuracy of 60%. Also notice the downstream model (the <code>glm</code>) erroneously thinks the <code>xBad?_cat</code> variables are significant (due to the large number of degrees of freedom hidden from the downstream model by the <a href="http://www.win-vector.com/blog/2012/07/modeling-trick-impact-coding-of-categorical-variables-with-many-levels/">impact/effect coding</a>).</p>
</div>
<div id="the-right-way-a-calibration-set" class="section level2">
<h2 class="hasAnchor">
<a href="#the-right-way-a-calibration-set" class="anchor"></a>The Right Way: A Calibration Set</h2>
<p>Now try a proper calibration/train/test split:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dCal &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'cal'</span>,,drop=<span class="ot">FALSE</span>]
dTrain &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'train'</span>,,drop=<span class="ot">FALSE</span>]
dTest &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]

<span class="co"># a nice heuristic, </span>
<span class="co"># expect only a constant number of noise variables to sneak past</span>
pruneSig &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">ncol</a></span>(dTrain) 
treatments &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/designTreatmentsC">designTreatmentsC</a></span>(dCal,
                                        <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'xBad1'</span>,<span class="st">'xBad2'</span>,<span class="st">'xBad3'</span>,<span class="st">'xGood1'</span>,<span class="st">'xGood2'</span>),
                                        <span class="st">'y'</span>,<span class="ot">TRUE</span>,
  <span class="dt">rareCount=</span><span class="dv">0</span> <span class="co"># Note: usually want rareCount&gt;0, setting to zero to illustrate problem</span>
)</code></pre></div>
<pre><code>## [1] "vtreat 1.3.6 inspecting inputs Sat Feb  9 10:25:59 2019"
## [1] "designing treatments Sat Feb  9 10:25:59 2019"
## [1] " have initial level statistics Sat Feb  9 10:25:59 2019"
## [1] " scoring treatments Sat Feb  9 10:25:59 2019"
## [1] "have treatment plan Sat Feb  9 10:25:59 2019"
## [1] "rescoring complex variables Sat Feb  9 10:25:59 2019"
## [1] "done rescoring complex variables Sat Feb  9 10:25:59 2019"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrainTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTrain,
  <span class="dt">pruneSig=</span>pruneSig)
newvars &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sets">setdiff</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/colnames">colnames</a></span>(dTrainTreated),<span class="st">'y'</span>)
m1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/glm">glm</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(<span class="st">'y'</span>,<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(newvars,<span class="dt">collapse=</span><span class="st">' + '</span>),<span class="dt">sep=</span><span class="st">' ~ '</span>),
          <span class="dt">data=</span>dTrainTreated,<span class="dt">family=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/family">binomial</a></span>(<span class="dt">link=</span><span class="st">'logit'</span>))
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(m1))  </code></pre></div>
<pre><code>## 
## Call:
## glm(formula = paste("y", paste(newvars, collapse = " + "), sep = " ~ "), 
##     family = binomial(link = "logit"), data = dTrainTreated)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5225  -0.9198  -0.6951   1.1703   2.2995  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.69527    0.08873  -7.836 4.65e-15 ***
## xGood1       0.39514    0.08537   4.629 3.68e-06 ***
## xGood2       0.55134    0.09580   5.755 8.66e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 832.55  on 642  degrees of freedom
## Residual deviance: 771.92  on 640  degrees of freedom
## AIC: 777.92
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(m1,<span class="dt">newdata=</span>dTrainTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTrain,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on train'</span>)</code></pre></div>
<pre><code>## [1] "model1 on train"
##        pred
## truth   FALSE TRUE
##   FALSE   377   41
##   TRUE    160   65
## [1] "accuracy 0.687402799377916"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTestTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTest,
                                <span class="dt">pruneSig=</span>pruneSig)
dTest<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(m1,<span class="dt">newdata=</span>dTestTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTest,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on test'</span>)</code></pre></div>
<pre><code>## [1] "model1 on test"
##        pred
## truth   FALSE TRUE
##   FALSE   425   49
##   TRUE    150   44
## [1] "accuracy 0.702095808383233"</code></pre>
<p>Notice above that we now see training and test accuracies of 70%. We have defeated over-fit in two ways: training performance is closer to test performance, and test performance is better. Also we see that the model now properly considers the “bad” variables to be insignificant.</p>
</div>
<div id="another-right-way-cross-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#another-right-way-cross-validation" class="anchor"></a>Another Right Way: Cross-Validation</h2>
<p>Below is a more statistically efficient practice: building a cross training frame.</p>
<div id="the-intuition" class="section level3">
<h3 class="hasAnchor">
<a href="#the-intuition" class="anchor"></a>The intuition</h3>
<p>Consider any trained statistical model (in this case our treatment plan and variable selection plan) as a two-argument function <em>f(A,B)</em>. The first argument is the training data and the second argument is the application data. In our case <em>f(A,B)</em> is: <code>designTreatmentsC(A) %&gt;% prepare(B)</code>, and it produces a treated data frame.</p>
<p>When we use the same data in both places to build our training frame, as in</p>
<blockquote>
<p><em>TrainTreated = f(TrainData,TrainData)</em>,</p>
</blockquote>
<p>we are not doing a good job simulating the future application of <em>f(,)</em>, which will be <em>f(TrainData,FutureData)</em>.</p>
<p>To improve the quality of our simulation we can call</p>
<blockquote>
<p><em>TrainTreated = f(CalibrationData,TrainData)</em></p>
</blockquote>
<p>where <em>CalibrationData</em> and <em>TrainData</em> are disjoint datasets (as we did in the earlier example) and expect this to be a good imitation of future <em>f(CalibrationData,FutureData)</em>.</p>
</div>
<div id="cross-validation-and-vtreat-the-cross-frame-" class="section level3">
<h3 class="hasAnchor">
<a href="#cross-validation-and-vtreat-the-cross-frame-" class="anchor"></a>Cross-Validation and vtreat: The cross-frame.</h3>
<p>Another approach is to build a “cross validated” version of <em>f</em>. We split <em>TrainData</em> into a list of 3 disjoint row intervals: <em>Train1</em>,<em>Train2</em>,<em>Train3</em>. Instead of computing <em>f(TrainData,TrainData)</em> compute:</p>
<blockquote>
<p><em>TrainTreated = f(Train2+Train3,Train1) + f(Train1+Train3,Train2) + f(Train1+Train2,Train3)</em></p>
</blockquote>
<p>(where + denotes <code><a href="https://www.rdocumentation.org/packages/base/topics/cbind">rbind()</a></code>).</p>
<p>The idea is this looks a lot like <em>f(TrainData,TrainData)</em> except it has the important property that no row in the right-hand side is ever worked on by a model built using that row (a key characteristic that future data will have) so we have a good imitation of <em>f(TrainData,FutureData)</em>.</p>
<p>In other words: we use cross validation to simulate future data. The main thing we are doing differently is remembering that we can apply cross validation to <em>any</em> two argument function <em>f(A,B)</em> and not only to functions of the form <em>f(A,B)</em> = <code>buildModel(A) %&gt;% scoreData(B)</code>. We can use this formulation in stacking or super-learning with <em>f(A,B)</em> of the form <code>buildSubModels(A) %&gt;% combineModels(B)</code> (to produce a stacked or ensemble model); the idea applies to improving ensemble methods in general.</p>
<p>See:</p>
<ul>
<li>“General oracle inequalities for model selection” Charles Mitchell and Sara van de Geer</li>
<li>“On Cross-Validation and Stacking: Building seemingly predictive models on random data” Claudia Perlich and Grzegorz Swirszcz</li>
<li>“Super Learner” Mark J. van der Laan, Eric C. Polley, and Alan E. Hubbard</li>
</ul>
<p>In fact you can think of vtreat as a super-learner.</p>
<p>In super learning cross validation techniques are used to simulate having built sub-model predictions on novel data. The simulated out of sample-applications of these sub models (and not the sub models themselves) are then used as input data for the next stage learner. In future application the actual sub-models are applied and their immediate outputs is used by the super model.</p>
<p><img src="superX.png" width="600"></p>
<p>In vtreat the sub-models are single variable treatments and the outer model construction is left to the practitioner (using the cross-frames for simulation and not the treatmentplan). In application the treatment plan is used.</p>
<p><img src="vtreatX.png" width="600"></p>
</div>
<div id="example" class="section level3">
<h3 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h3>
<p>Below is the example cross-run. The function <code>mkCrossFrameCExperiment</code> returns a treatment plan for use in preparing future data, and a cross-frame for use in fitting a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">!=</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
dTest &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
prep &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/mkCrossFrameCExperiment">mkCrossFrameCExperiment</a></span>(dTrain,
           <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'xBad1'</span>,<span class="st">'xBad2'</span>,<span class="st">'xBad3'</span>,<span class="st">'xGood1'</span>,<span class="st">'xGood2'</span>),
           <span class="st">'y'</span>,<span class="ot">TRUE</span>,
           <span class="dt">rareCount=</span><span class="dv">0</span> <span class="co"># Note: usually want rareCount&gt;0, setting to zero to illustrate problems</span>
)</code></pre></div>
<pre><code>## [1] "vtreat 1.3.6 start initial treatment design Sat Feb  9 10:25:59 2019"
## [1] " start cross frame work Sat Feb  9 10:26:00 2019"
## [1] " vtreat::mkCrossFrameCExperiment done Sat Feb  9 10:26:00 2019"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">treatments &lt;-<span class="st"> </span>prep<span class="op">$</span>treatments

knitr<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/knitr/topics/kable">kable</a></span>(treatments<span class="op">$</span>scoreFrame[,<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'varName'</span>,<span class="st">'sig'</span>)])</code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="left">varName</th>
<th align="right">sig</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">xBad1_catP</td>
<td align="right">0.8685784</td>
</tr>
<tr class="even">
<td align="left">xBad1_catB</td>
<td align="right">0.0942444</td>
</tr>
<tr class="odd">
<td align="left">xBad2_catP</td>
<td align="right">0.8558471</td>
</tr>
<tr class="even">
<td align="left">xBad2_catB</td>
<td align="right">0.1142775</td>
</tr>
<tr class="odd">
<td align="left">xBad3_catP</td>
<td align="right">0.6981315</td>
</tr>
<tr class="even">
<td align="left">xBad3_catB</td>
<td align="right">0.1103321</td>
</tr>
<tr class="odd">
<td align="left">xGood1</td>
<td align="right">0.0000000</td>
</tr>
<tr class="even">
<td align="left">xGood2</td>
<td align="right">0.0000000</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/colnames">colnames</a></span>(prep<span class="op">$</span>crossFrame)</code></pre></div>
<pre><code>## [1] "xBad1_catP" "xBad1_catB" "xBad2_catP" "xBad2_catB" "xBad3_catP"
## [6] "xBad3_catB" "xGood1"     "xGood2"     "y"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># vtreat::mkCrossFrameCExperiment doesn't take a pruneSig argument, but we can</span>
<span class="co"># prune on our own.</span>
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(pruneSig)</code></pre></div>
<pre><code>## [1] 0.1428571</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newvars &lt;-<span class="st"> </span>treatments<span class="op">$</span>scoreFrame<span class="op">$</span>varName[treatments<span class="op">$</span>scoreFrame<span class="op">$</span>sig<span class="op">&lt;=</span>pruneSig]
<span class="co"># force in bad variables, to show we "belt and suspenders" deal with them</span>
<span class="co"># in that things go well in the cross-frame even if they sneak past pruning</span>
newvars &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sort">sort</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sets">union</a></span>(newvars,<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"xBad1_catB"</span>,<span class="st">"xBad2_catB"</span>,<span class="st">"xBad3_catB"</span>)))
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(newvars)</code></pre></div>
<pre><code>## [1] "xBad1_catB" "xBad2_catB" "xBad3_catB" "xGood1"     "xGood2"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrainTreated &lt;-<span class="st"> </span>prep<span class="op">$</span>crossFrame</code></pre></div>
<p>We ensured the undesirable <code>xBad*_catB</code> variables back in to demonstrate that even if they sneak past a lose <code>pruneSig</code>, the crossframe lets the downstream model deal with them correctly. To ensure more consistent filtering of the complicated variables one can increase the <code>ncross</code> argument in <code><a href="../reference/mkCrossFrameCExperiment.html">vtreat::mkCrossFrameCExperiment</a></code>/<code><a href="../reference/mkCrossFrameNExperiment.html">vtreat::mkCrossFrameNExperiment</a></code>.</p>
<p>Now we fit the model to <em>the cross-frame</em> rather than to <code><a href="../reference/prepare.html">prepare(treatments, dTrain)</a></code> (the treated training data).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/glm">glm</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(<span class="st">'y'</span>,<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(newvars,<span class="dt">collapse=</span><span class="st">' + '</span>),<span class="dt">sep=</span><span class="st">' ~ '</span>),
          <span class="dt">data=</span>dTrainTreated,<span class="dt">family=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/family">binomial</a></span>(<span class="dt">link=</span><span class="st">'logit'</span>))
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(m1))  </code></pre></div>
<pre><code>## 
## Call:
## glm(formula = paste("y", paste(newvars, collapse = " + "), sep = " ~ "), 
##     family = binomial(link = "logit"), data = dTrainTreated)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6624  -0.9170  -0.6663   1.1747   2.2971  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.687112   0.065340 -10.516  &lt; 2e-16 ***
## xBad1_catB   0.007962   0.009466   0.841    0.400    
## xBad2_catB  -0.014104   0.009579  -1.472    0.141    
## xBad3_catB   0.014359   0.009331   1.539    0.124    
## xGood1       0.405918   0.061888   6.559 5.42e-11 ***
## xGood2       0.570827   0.064946   8.789  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1724.6  on 1331  degrees of freedom
## Residual deviance: 1586.6  on 1326  degrees of freedom
## AIC: 1598.6
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(m1,<span class="dt">newdata=</span>dTrainTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTrain,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on train'</span>)</code></pre></div>
<pre><code>## [1] "model1 on train"
##        pred
## truth   FALSE TRUE
##   FALSE   775   91
##   TRUE    331  135
## [1] "accuracy 0.683183183183183"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTestTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTest,
                                <span class="dt">pruneSig=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(),<span class="dt">varRestriction=</span>newvars)
knitr<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/knitr/topics/kable">kable</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/head">head</a></span>(dTestTreated))</code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">xBad1_catB</th>
<th align="right">xBad2_catB</th>
<th align="right">xBad3_catB</th>
<th align="right">xGood1</th>
<th align="right">xGood2</th>
<th align="left">y</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">0.0000000</td>
<td align="right">0.6196992</td>
<td align="right">-8.590741</td>
<td align="right">0.4217559</td>
<td align="right">0.3143976</td>
<td align="left">TRUE</td>
</tr>
<tr class="even">
<td align="right">-8.5907412</td>
<td align="right">0.0000000</td>
<td align="right">-9.283838</td>
<td align="right">-1.6801750</td>
<td align="right">-0.0767822</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="right">-9.6892868</td>
<td align="right">0.0000000</td>
<td align="right">9.830139</td>
<td align="right">1.0637346</td>
<td align="right">0.8217212</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="right">9.8301395</td>
<td align="right">-0.0733980</td>
<td align="right">-8.590741</td>
<td align="right">0.2954393</td>
<td align="right">0.3517839</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="right">-9.2838384</td>
<td align="right">-8.5907412</td>
<td align="right">0.000000</td>
<td align="right">0.9866599</td>
<td align="right">0.3880777</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="right">0.6196992</td>
<td align="right">9.8301395</td>
<td align="right">9.830139</td>
<td align="right">1.1893923</td>
<td align="right">0.3922303</td>
<td align="left">TRUE</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTest<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(m1,<span class="dt">newdata=</span>dTestTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTest,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on test'</span>)</code></pre></div>
<pre><code>## [1] "model1 on test"
##        pred
## truth   FALSE TRUE
##   FALSE   421   53
##   TRUE    145   49
## [1] "accuracy 0.703592814371258"</code></pre>
<p>We again get the better 70% test accuracy. And this is a more statistically efficient technique as we didn’t have to restrict some data to calibration.</p>
<p>The model fit to the cross-frame behaves similarly to the model produced via the process <em>f(CalibrationData, TrainData)</em>. Notice that the <code>xBad*_catB</code> variables fail to achieve significance in the downstream <code>glm</code> model, allowing that model to give them small coefficients and even (if need be) prune them out. This is the point of using a cross frame as we see in the first example the <code>xBad*_catB</code> are hard to remove if they make it to standard (non-cross) frames as they are hiding a lot of degrees of freedom from downstream modeling procedures.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#the-wrong-way">The Wrong Way</a></li>
      <li><a href="#the-right-way-a-calibration-set">The Right Way: A Calibration Set</a></li>
      <li><a href="#another-right-way-cross-validation">Another Right Way: Cross-Validation</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by John Mount, Nina Zumel.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>

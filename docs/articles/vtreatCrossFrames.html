<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>vtreat cross frames • vtreat</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><meta property="og:title" content="vtreat cross frames">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">vtreat</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">1.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/vtreat.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/SavingTreamentPlans.html">Saving Treatment Plans</a>
    </li>
    <li>
      <a href="../articles/vtreatCrossFrames.html">vtreat cross frames</a>
    </li>
    <li>
      <a href="../articles/vtreatGrouping.html">Grouping Example</a>
    </li>
    <li>
      <a href="../articles/vtreatOverfit.html">vtreat overfit</a>
    </li>
    <li>
      <a href="../articles/vtreatRareLevels.html">vtreat Rare Levels</a>
    </li>
    <li>
      <a href="../articles/vtreatScaleMode.html">vtreat scale mode</a>
    </li>
    <li>
      <a href="../articles/vtreatSignificance.html">vtreat significance</a>
    </li>
    <li>
      <a href="../articles/vtreatSplitting.html">vtreat splitting</a>
    </li>
    <li>
      <a href="../articles/vtreatVariableTypes.html">Variable Types</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="http://www.win-vector.com/">Sponsor: Win-Vector LLC</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>vtreat cross frames</h1>
                        <h4 class="author">John Mount, Nina Zumel</h4>
            
            <h4 class="date">2018-06-14</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/WinVector/vtreat//blob/master/vignettes/vtreatCrossFrames.Rmd"><code>vignettes/vtreatCrossFrames.Rmd</code></a></small>
      <div class="hidden name"><code>vtreatCrossFrames.Rmd</code></div>

    </div>

    
    
<p>Example demonstrating “cross validated training frames” (or “cross frames”) in vtreat.</p>
<p>Consider the following data frame. The outcome only depends on the “good” variables, not on the (high degree of freedom) “bad” variables. Modeling such a data set runs a high risk of overfit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">22626</span>)

mkData &lt;-<span class="st"> </span><span class="cf">function</span>(n) {
  d &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">xBad1=</span><span class="kw">sample</span>(<span class="kw">paste</span>(<span class="st">'level'</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,<span class="dt">sep=</span><span class="st">''</span>),n,<span class="dt">replace=</span><span class="ot">TRUE</span>),
                  <span class="dt">xBad2=</span><span class="kw">sample</span>(<span class="kw">paste</span>(<span class="st">'level'</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,<span class="dt">sep=</span><span class="st">''</span>),n,<span class="dt">replace=</span><span class="ot">TRUE</span>),
                  <span class="dt">xBad3=</span><span class="kw">sample</span>(<span class="kw">paste</span>(<span class="st">'level'</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,<span class="dt">sep=</span><span class="st">''</span>),n,<span class="dt">replace=</span><span class="ot">TRUE</span>),
                  <span class="dt">xGood1=</span><span class="kw">rnorm</span>(n),
                  <span class="dt">xGood2=</span><span class="kw">rnorm</span>(n))
  
  <span class="co"># outcome only depends on "good" variables</span>
  d<span class="op">$</span>y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">nrow</span>(d))<span class="op">+</span><span class="fl">0.2</span><span class="op">*</span>d<span class="op">$</span>xGood1 <span class="op">+</span><span class="st"> </span><span class="fl">0.3</span><span class="op">*</span>d<span class="op">$</span>xGood2<span class="op">&gt;</span><span class="fl">0.5</span>
  <span class="co"># the random group used for splitting the data set, not a variable.</span>
  d<span class="op">$</span>rgroup &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">"cal"</span>,<span class="st">"train"</span>,<span class="st">"test"</span>),<span class="kw">nrow</span>(d),<span class="dt">replace=</span><span class="ot">TRUE</span>)  
  d
}

d &lt;-<span class="st"> </span><span class="kw">mkData</span>(<span class="dv">2000</span>)

<span class="co"># devtools::install_github("WinVector/WVPlots")</span>
<span class="co"># library('WVPlots')</span>
plotRes &lt;-<span class="st"> </span><span class="cf">function</span>(d,predName,yName,title) {
  <span class="kw">print</span>(title)
  tab &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="dt">truth=</span>d[[yName]],<span class="dt">pred=</span>d[[predName]]<span class="op">&gt;</span><span class="fl">0.5</span>)
  <span class="kw">print</span>(tab)
  diag &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">vapply</span>(<span class="kw">seq_len</span>(<span class="kw">min</span>(<span class="kw">dim</span>(tab))),
                     <span class="cf">function</span>(i) tab[i,i],<span class="kw">numeric</span>(<span class="dv">1</span>)))
  acc &lt;-<span class="st"> </span>diag<span class="op">/</span><span class="kw">sum</span>(tab)
<span class="co">#  if(requireNamespace("WVPlots",quietly=TRUE)) {</span>
<span class="co">#     print(WVPlots::ROCPlot(d,predName,yName,title))</span>
<span class="co">#  }</span>
  <span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">'accuracy'</span>,acc))
}</code></pre></div>
<div id="the-wrong-way" class="section level2">
<h2 class="hasAnchor">
<a href="#the-wrong-way" class="anchor"></a>The Wrong Way</h2>
<p>Bad practice: use the same set of data to prepare variable encoding and train a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">!=</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
dTest &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
treatments &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/designTreatmentsC">designTreatmentsC</a></span>(dTrain,<span class="kw">c</span>(<span class="st">'xBad1'</span>,<span class="st">'xBad2'</span>,<span class="st">'xBad3'</span>,<span class="st">'xGood1'</span>,<span class="st">'xGood2'</span>),
                                        <span class="st">'y'</span>,<span class="ot">TRUE</span>,
  <span class="dt">rareCount=</span><span class="dv">0</span> <span class="co"># Note: usually want rareCount&gt;0, setting to zero to illustrate problem</span>
)</code></pre></div>
<pre><code>## [1] "vtreat 1.2.0 inspecting inputs Thu Jun 14 14:55:24 2018"
## [1] "designing treatments Thu Jun 14 14:55:24 2018"
## [1] " have initial level statistics Thu Jun 14 14:55:24 2018"
## [1] "design var xBad1 Thu Jun 14 14:55:24 2018"
## [1] "design var xBad2 Thu Jun 14 14:55:24 2018"
## [1] "design var xBad3 Thu Jun 14 14:55:24 2018"
## [1] "design var xGood1 Thu Jun 14 14:55:24 2018"
## [1] "design var xGood2 Thu Jun 14 14:55:24 2018"
## [1] " scoring treatments Thu Jun 14 14:55:24 2018"
## [1] "have treatment plan Thu Jun 14 14:55:25 2018"
## [1] "rescoring complex variables Thu Jun 14 14:55:25 2018"
## [1] "done rescoring complex variables Thu Jun 14 14:55:25 2018"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrainTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTrain,
  <span class="dt">pruneSig=</span><span class="kw">c</span>() <span class="co"># Note: usually want pruneSig to be a small fraction, setting to null to illustrate problems</span>
)
m1 &lt;-<span class="st"> </span><span class="kw">glm</span>(y<span class="op">~</span>xBad1_catB <span class="op">+</span><span class="st"> </span>xBad2_catB <span class="op">+</span><span class="st"> </span>xBad3_catB <span class="op">+</span><span class="st"> </span>xGood1_clean <span class="op">+</span><span class="st"> </span>xGood2_clean,
          <span class="dt">data=</span>dTrainTreated,<span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'logit'</span>))</code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">summary</span>(m1))  <span class="co"># notice low residual deviance</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = y ~ xBad1_catB + xBad2_catB + xBad3_catB + xGood1_clean + 
##     xGood2_clean, family = binomial(link = "logit"), data = dTrainTreated)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.32190  -0.00014   0.00000   0.00001   2.32399  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   -0.5794     0.3284  -1.764 0.077698 .  
## xBad1_catB     1.0987     0.3627   3.029 0.002454 ** 
## xBad2_catB     0.9302     0.3058   3.042 0.002349 ** 
## xBad3_catB     1.5057     0.4468   3.370 0.000752 ***
## xGood1_clean   0.8404     0.2619   3.209 0.001334 ** 
## xGood2_clean   0.8254     0.2854   2.892 0.003823 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1724.55  on 1331  degrees of freedom
## Residual deviance:  114.93  on 1326  degrees of freedom
## AIC: 126.93
## 
## Number of Fisher Scoring iterations: 12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw">predict</span>(m1,<span class="dt">newdata=</span>dTrainTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTrain,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on train'</span>)</code></pre></div>
<pre><code>## [1] "model1 on train"
##        pred
## truth   FALSE TRUE
##   FALSE   850   16
##   TRUE      7  459
## [1] "accuracy 0.982732732732733"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTestTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTest,<span class="dt">pruneSig=</span><span class="kw">c</span>())
dTest<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw">predict</span>(m1,<span class="dt">newdata=</span>dTestTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTest,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on test'</span>)</code></pre></div>
<pre><code>## [1] "model1 on test"
##        pred
## truth   FALSE TRUE
##   FALSE   316  158
##   TRUE    134   60
## [1] "accuracy 0.562874251497006"</code></pre>
<p>Notice above that we see a training accuracy of 98% and a test accuracy of 60%. Also notice the downstream model (the <code>glm</code>) erroneously thinks the <code>xBad?_cat</code> variables are significant (due to the large number of degrees of freedom hidden from the downstream model by the <a href="http://www.win-vector.com/blog/2012/07/modeling-trick-impact-coding-of-categorical-variables-with-many-levels/">impact/effect coding</a>).</p>
</div>
<div id="the-right-way-a-calibration-set" class="section level2">
<h2 class="hasAnchor">
<a href="#the-right-way-a-calibration-set" class="anchor"></a>The Right Way: A Calibration Set</h2>
<p>Now try a proper calibration/train/test split:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dCal &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'cal'</span>,,drop=<span class="ot">FALSE</span>]
dTrain &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'train'</span>,,drop=<span class="ot">FALSE</span>]
dTest &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]

<span class="co"># a nice heuristic, </span>
<span class="co"># expect only a constant number of noise variables to sneak past</span>
pruneSig &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw">ncol</span>(dTrain) 
treatments &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/designTreatmentsC">designTreatmentsC</a></span>(dCal,
                                        <span class="kw">c</span>(<span class="st">'xBad1'</span>,<span class="st">'xBad2'</span>,<span class="st">'xBad3'</span>,<span class="st">'xGood1'</span>,<span class="st">'xGood2'</span>),
                                        <span class="st">'y'</span>,<span class="ot">TRUE</span>,
  <span class="dt">rareCount=</span><span class="dv">0</span> <span class="co"># Note: usually want rareCount&gt;0, setting to zero to illustrate problem</span>
)</code></pre></div>
<pre><code>## [1] "vtreat 1.2.0 inspecting inputs Thu Jun 14 14:55:25 2018"
## [1] "designing treatments Thu Jun 14 14:55:25 2018"
## [1] " have initial level statistics Thu Jun 14 14:55:25 2018"
## [1] "design var xBad1 Thu Jun 14 14:55:25 2018"
## [1] "design var xBad2 Thu Jun 14 14:55:25 2018"
## [1] "design var xBad3 Thu Jun 14 14:55:25 2018"
## [1] "design var xGood1 Thu Jun 14 14:55:25 2018"
## [1] "design var xGood2 Thu Jun 14 14:55:25 2018"
## [1] " scoring treatments Thu Jun 14 14:55:25 2018"
## [1] "have treatment plan Thu Jun 14 14:55:25 2018"
## [1] "rescoring complex variables Thu Jun 14 14:55:25 2018"
## [1] "done rescoring complex variables Thu Jun 14 14:55:25 2018"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrainTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTrain,
  <span class="dt">pruneSig=</span>pruneSig)
newvars &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(dTrainTreated),<span class="st">'y'</span>)
m1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">paste</span>(<span class="st">'y'</span>,<span class="kw">paste</span>(newvars,<span class="dt">collapse=</span><span class="st">' + '</span>),<span class="dt">sep=</span><span class="st">' ~ '</span>),
          <span class="dt">data=</span>dTrainTreated,<span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'logit'</span>))
<span class="kw">print</span>(<span class="kw">summary</span>(m1))  </code></pre></div>
<pre><code>## 
## Call:
## glm(formula = paste("y", paste(newvars, collapse = " + "), sep = " ~ "), 
##     family = binomial(link = "logit"), data = dTrainTreated)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5225  -0.9198  -0.6951   1.1703   2.2995  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -0.69527    0.08873  -7.836 4.65e-15 ***
## xGood1_clean  0.39514    0.08537   4.629 3.68e-06 ***
## xGood2_clean  0.55134    0.09580   5.755 8.66e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 832.55  on 642  degrees of freedom
## Residual deviance: 771.92  on 640  degrees of freedom
## AIC: 777.92
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw">predict</span>(m1,<span class="dt">newdata=</span>dTrainTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTrain,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on train'</span>)</code></pre></div>
<pre><code>## [1] "model1 on train"
##        pred
## truth   FALSE TRUE
##   FALSE   377   41
##   TRUE    160   65
## [1] "accuracy 0.687402799377916"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTestTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTest,
                                <span class="dt">pruneSig=</span>pruneSig)
dTest<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw">predict</span>(m1,<span class="dt">newdata=</span>dTestTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTest,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on test'</span>)</code></pre></div>
<pre><code>## [1] "model1 on test"
##        pred
## truth   FALSE TRUE
##   FALSE   425   49
##   TRUE    150   44
## [1] "accuracy 0.702095808383233"</code></pre>
<p>Notice above that we now see training and test accuracies of 70%. We have defeated overfit in two ways: training performance is closer to test performance, and test performance is better. Also we see that the model now properly considers the “bad” variables to be insignificant.</p>
</div>
<div id="another-right-way-cross-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#another-right-way-cross-validation" class="anchor"></a>Another Right Way: Cross-Validation</h2>
<p>Below is a more statistically efficient practice: building a cross training frame.</p>
<div id="the-intuition" class="section level3">
<h3 class="hasAnchor">
<a href="#the-intuition" class="anchor"></a>The intuition</h3>
<p>Consider any trained statistical model (in this case our treatment plan and variable selection plan) as a two-argument function <em>f(A,B)</em>. The first argument is the training data and the second argument is the application data. In our case <em>f(A,B)</em> is: <code>designTreatmentsC(A) %&gt;% prepare(B)</code>, and it produces a treated data frame.</p>
<p>When we use the same data in both places to build our training frame, as in</p>
<blockquote>
<p><em>TrainTreated = f(TrainData,TrainData)</em>,</p>
</blockquote>
<p>we are not doing a good job simulating the future application of <em>f(,)</em>, which will be <em>f(TrainData,FutureData)</em>.</p>
<p>To improve the quality of our simulation we can call</p>
<blockquote>
<p><em>TrainTreated = f(CalibrationData,TrainData)</em></p>
</blockquote>
<p>where <em>CalibrationData</em> and <em>TrainData</em> are disjoint datasets (as we did in the earlier example) and expect this to be a good imitation of future <em>f(CalibrationData,FutureData)</em>.</p>
</div>
<div id="cross-validation-and-vtreat-the-cross-frame-" class="section level3">
<h3 class="hasAnchor">
<a href="#cross-validation-and-vtreat-the-cross-frame-" class="anchor"></a>Cross-Validation and vtreat: The cross-frame.</h3>
<p>Another approach is to build a “cross validated” version of <em>f</em>. We split <em>TrainData</em> into a list of 3 disjoint row intervals: <em>Train1</em>,<em>Train2</em>,<em>Train3</em>. Instead of computing <em>f(TrainData,TrainData)</em> compute:</p>
<blockquote>
<p><em>TrainTreated = f(Train2+Train3,Train1) + f(Train1+Train3,Train2) + f(Train1+Train2,Train3)</em></p>
</blockquote>
<p>(where + denotes <code>rbind()</code>).</p>
<p>The idea is this looks a lot like <em>f(TrainData,TrainData)</em> except it has the important property that no row in the right-hand side is ever worked on by a model built using that row (a key characteristic that future data will have) so we have a good imitation of <em>f(TrainData,FutureData)</em>.</p>
<p>In other words: we use cross validation to simulate future data. The main thing we are doing differently is remembering that we can apply cross validation to <em>any</em> two argument function <em>f(A,B)</em> and not only to functions of the form <em>f(A,B)</em> = <code>buildModel(A) %&gt;% scoreData(B)</code>. We can use this formulation in stacking or super-learning with <em>f(A,B)</em> of the form <code>buildSubModels(A) %&gt;% combineModels(B)</code> (to produce a stacked or ensemble model); the idea applies to improving ensemble methods in general.</p>
<p>See:</p>
<ul>
<li>“General oracle inequalities for model selection” Charles Mitchell and Sara van de Geer</li>
<li>“On Cross-Validation and Stacking: Building seemingly predictive models on random data” Claudia Perlich and Grzegorz Swirszcz</li>
<li>“Super Learner” Mark J. van der Laan, Eric C. Polley, and Alan E. Hubbard</li>
</ul>
<p>In fact you can think of vtreat as a superlearner.</p>
<p>In super learning cross validation techniques are used to simulate having built sub-model predictions on novel data. The simulated out of sample-applications of these sub models (and not the sub models themselves) are then used as input data for the next stage learner. In future application the actual sub-models are applied and their immediate outputs is used by the super model.</p>
<p><img src="superX.png" width="600"></p>
<p>In vtreat the sub-models are single variable treatments and the outer model construction is left to the practitioner (using the cross-frames for simulation and not the treatmentplan). In application the treatment plan is used.</p>
<p><img src="vtreatX.png" width="600"></p>
</div>
<div id="example" class="section level3">
<h3 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h3>
<p>Below is the example cross-run. The function <code>mkCrossFrameCExperiment</code> returns a treatment plan for use in preparing future data, and a cross-frame for use in fitting a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">!=</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
dTest &lt;-<span class="st"> </span>d[d<span class="op">$</span>rgroup<span class="op">==</span><span class="st">'test'</span>,,drop=<span class="ot">FALSE</span>]
prep &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/mkCrossFrameCExperiment">mkCrossFrameCExperiment</a></span>(dTrain,
           <span class="kw">c</span>(<span class="st">'xBad1'</span>,<span class="st">'xBad2'</span>,<span class="st">'xBad3'</span>,<span class="st">'xGood1'</span>,<span class="st">'xGood2'</span>),
           <span class="st">'y'</span>,<span class="ot">TRUE</span>,
           <span class="dt">rareCount=</span><span class="dv">0</span> <span class="co"># Note: usually want rareCount&gt;0, setting to zero to illustrate problems</span>
)</code></pre></div>
<pre><code>## [1] "vtreat 1.2.0 start initial treatment design Thu Jun 14 14:55:25 2018"
## [1] " start cross frame work Thu Jun 14 14:55:26 2018"
## [1] " vtreat::mkCrossFrameCExperiment done Thu Jun 14 14:55:26 2018"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">treatments &lt;-<span class="st"> </span>prep<span class="op">$</span>treatments
<span class="kw">print</span>(treatments<span class="op">$</span>scoreFrame[,<span class="kw">c</span>(<span class="st">'varName'</span>,<span class="st">'sig'</span>)])</code></pre></div>
<pre><code>##        varName          sig
## 1   xBad1_catP 9.578124e-01
## 2   xBad1_catB 9.424435e-02
## 3   xBad2_catP 7.496971e-01
## 4   xBad2_catB 1.142775e-01
## 5   xBad3_catP 7.419157e-01
## 6   xBad3_catB 1.103321e-01
## 7 xGood1_clean 6.072599e-12
## 8 xGood2_clean 8.286789e-21</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># vtreat::mkCrossFrameCExperiment doesn't take a pruneSig argument, but we can</span>
<span class="co"># prune on our own.</span>
<span class="kw">print</span>(pruneSig)</code></pre></div>
<pre><code>## [1] 0.1428571</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newvars &lt;-<span class="st"> </span>treatments<span class="op">$</span>scoreFrame<span class="op">$</span>varName[treatments<span class="op">$</span>scoreFrame<span class="op">$</span>sig<span class="op">&lt;=</span>pruneSig]
<span class="co"># force in bad variables, to show we "belt and suspenders" deal with them</span>
<span class="co"># in that things go well in the cross-frame even if they sneak past pruning</span>
newvars &lt;-<span class="st"> </span><span class="kw">sort</span>(<span class="kw">union</span>(newvars,<span class="kw">c</span>(<span class="st">"xBad1_catB"</span>,<span class="st">"xBad2_catB"</span>,<span class="st">"xBad3_catB"</span>)))
<span class="kw">print</span>(newvars)</code></pre></div>
<pre><code>## [1] "xBad1_catB"   "xBad2_catB"   "xBad3_catB"   "xGood1_clean"
## [5] "xGood2_clean"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrainTreated &lt;-<span class="st"> </span>prep<span class="op">$</span>crossFrame</code></pre></div>
<p>We ensured the undesirable <code>xBad*_catB</code> variables back in to demonstrate that even if they sneak past a lose <code>pruneSig</code>, the crosframe lets the downstream model deal with them correctly. To ensure more consistent filtering of the complicated variables one can increase the <code>ncross</code> argument in <code><a href="../reference/mkCrossFrameCExperiment.html">vtreat::mkCrossFrameCExperiment</a></code>/<code><a href="../reference/mkCrossFrameNExperiment.html">vtreat::mkCrossFrameNExperiment</a></code>.</p>
<p>Now we fit the model to <em>the cross-frame</em> rather than to <code><a href="../reference/prepare.html">prepare(treatments, dTrain)</a></code> (the treated training data).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">paste</span>(<span class="st">'y'</span>,<span class="kw">paste</span>(newvars,<span class="dt">collapse=</span><span class="st">' + '</span>),<span class="dt">sep=</span><span class="st">' ~ '</span>),
          <span class="dt">data=</span>dTrainTreated,<span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'logit'</span>))
<span class="kw">print</span>(<span class="kw">summary</span>(m1))  </code></pre></div>
<pre><code>## 
## Call:
## glm(formula = paste("y", paste(newvars, collapse = " + "), sep = " ~ "), 
##     family = binomial(link = "logit"), data = dTrainTreated)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6624  -0.9170  -0.6663   1.1747   2.2971  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -0.687112   0.065340 -10.516  &lt; 2e-16 ***
## xBad1_catB    0.007962   0.009466   0.841    0.400    
## xBad2_catB   -0.014104   0.009579  -1.472    0.141    
## xBad3_catB    0.014359   0.009331   1.539    0.124    
## xGood1_clean  0.405918   0.061888   6.559 5.42e-11 ***
## xGood2_clean  0.570827   0.064946   8.789  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1724.6  on 1331  degrees of freedom
## Residual deviance: 1586.6  on 1326  degrees of freedom
## AIC: 1598.6
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTrain<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw">predict</span>(m1,<span class="dt">newdata=</span>dTrainTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTrain,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on train'</span>)</code></pre></div>
<pre><code>## [1] "model1 on train"
##        pred
## truth   FALSE TRUE
##   FALSE   775   91
##   TRUE    331  135
## [1] "accuracy 0.683183183183183"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dTestTreated &lt;-<span class="st"> </span>vtreat<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/vtreat/topics/prepare">prepare</a></span>(treatments,dTest,
                                <span class="dt">pruneSig=</span><span class="kw">c</span>(),<span class="dt">varRestriction=</span>newvars)
dTest<span class="op">$</span>predM1 &lt;-<span class="st"> </span><span class="kw">predict</span>(m1,<span class="dt">newdata=</span>dTestTreated,<span class="dt">type=</span><span class="st">'response'</span>)
<span class="kw">plotRes</span>(dTest,<span class="st">'predM1'</span>,<span class="st">'y'</span>,<span class="st">'model1 on test'</span>)</code></pre></div>
<pre><code>## [1] "model1 on test"
##        pred
## truth   FALSE TRUE
##   FALSE   421   53
##   TRUE    145   49
## [1] "accuracy 0.703592814371258"</code></pre>
<p>We again get the better 70% test accuracy. And this is a more statistically efficient technique as we didn’t have to restrict some data to calibration.</p>
<p>The model fit to the cross-frame behaves similarly to the model produced via the process <em>f(CalibrationData, TrainData)</em>. Notice that the <code>xBad*_catB</code> variables fail to achieve significance in the downstream <code>glm</code> model, allowing that model to give them small coefficients and even (if need be) prune them out. This is the point of using a cross frame as we see in the first example the <code>xBad*_catB</code> are hard to remove if they make it to standard (non-cross) frames as they are hiding a lot of degrees of freedom from downstream modeling procedures.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#the-wrong-way">The Wrong Way</a></li>
      <li><a href="#the-right-way-a-calibration-set">The Right Way: A Calibration Set</a></li>
      <li><a href="#another-right-way-cross-validation">Another Right Way: Cross-Validation</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by John Mount, Nina Zumel.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>

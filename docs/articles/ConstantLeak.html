<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Constant Coding Leak • vtreat</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">vtreat</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/vtreat.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/ConstantLeak.html">Constant Coding Leak</a>
    </li>
    <li>
      <a href="../articles/CustomLevelCoders.html">Custom Level Coding in vtreat</a>
    </li>
    <li>
      <a href="../articles/SavingTreamentPlans.html">Saving Treatment Plans</a>
    </li>
    <li>
      <a href="../articles/vtreatCrossFrames.html">vtreat cross frames</a>
    </li>
    <li>
      <a href="../articles/vtreatGrouping.html">Grouping Example</a>
    </li>
    <li>
      <a href="../articles/vtreatOverfit.html">vtreat overfit</a>
    </li>
    <li>
      <a href="../articles/vtreatRareLevels.html">vtreat Rare Levels</a>
    </li>
    <li>
      <a href="../articles/vtreatScaleMode.html">vtreat scale mode</a>
    </li>
    <li>
      <a href="../articles/vtreatSignificance.html">vtreat significance</a>
    </li>
    <li>
      <a href="../articles/vtreatSplitting.html">vtreat splitting</a>
    </li>
    <li>
      <a href="../articles/vtreatVariableTypes.html">Variable Types</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="http://www.win-vector.com/">Sponsor: Win-Vector LLC</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Constant Coding Leak</h1>
                        <h4 class="author">John Mount, Win-Vector LLC</h4>
            
            <h4 class="date">2017-09-18</h4>
          </div>

    
    
<div class="contents">
<p>We will show how in some situations using “more data in cross-validation” can be harmful.</p>
<p>Our example: an outcome (<code>y</code>) that is independent of a low-complexity categorical variable (<code>x</code>). We will combine this with a varaible that is a noisy constant and leave-one-out cross-validation (which is a deterministic procedure) to get a bad result (failing to notice over-fit).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"vtreat"</span>)

<span class="kw">set.seed</span>(<span class="dv">352355</span>)

nrow &lt;-<span class="st"> </span><span class="dv">100</span>
d &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">'a'</span>, <span class="st">'b'</span>), 
                           nrow, <span class="dt">replace =</span> <span class="ot">TRUE</span>),
                <span class="dt">y =</span> <span class="kw">rnorm</span>(nrow),
                <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Introduce a deliberately bad custom coder.</p>
<p>This coder is bad in several ways:</p>
<ul>
<li>It is essentially returning a constant independent of the variable it claims to be encoding.</li>
<li>It’s predictions are not consistent, it makes different predictions for the same value of the independent variable it claims to encode.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @param v character scalar: variable name</span>
<span class="co"># @param vcol character vector, independent or input variable values</span>
<span class="co"># @param y numeric, dependent or outcome variable to predict</span>
<span class="co"># @param weights row/example weights</span>
<span class="co"># @return scored training data column</span>
badCoderN &lt;-<span class="st"> </span>function(v, vcol, 
                      y, 
                      weights) {
  <span class="co"># Notice we are returning a constant, independent of vcol!</span>
  <span class="co"># this should not look informative.</span>
  meanY &lt;-<span class="st"> </span><span class="kw">sum</span>(y*weights)/<span class="kw">sum</span>(weights)
  <span class="fl">1.0e-3</span>*<span class="kw">runif</span>(<span class="kw">length</span>(y)) +<span class="st"> </span>meanY <span class="co"># noise to sneak past constant detector</span>
}

customCoders &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">'n.badCoderN'</span> =<span class="st"> </span>badCoderN)</code></pre></div>
<p><code>vtreat</code> correctly works on this example in the design/prepare pattern, and rejects the bad custom variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">treatplanN &lt;-<span class="st"> </span><span class="kw"><a href="../reference/designTreatmentsN.html">designTreatmentsN</a></span>(d, 
                                <span class="dt">varlist =</span> <span class="kw">c</span>(<span class="st">'x'</span>),
                                <span class="dt">outcomename =</span> <span class="st">'y'</span>,
                                <span class="dt">codeRestriction =</span> <span class="st">'badCoderN'</span>,
                                <span class="dt">customCoders =</span> customCoders, 
                                <span class="dt">verbose =</span> <span class="ot">FALSE</span>)
<span class="kw">t</span>(treatplanN$scoreFrame)</code></pre></div>
<pre><code>##                   1            
## varName           "x_badCoderN"
## varMoves          "TRUE"       
## rsq               "0.001342833"
## sig               "0.7173809"  
## needsSplit        "TRUE"       
## extraModelDegrees "1"          
## origName          "x"          
## code              "badCoderN"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">treatedD &lt;-<span class="st"> </span><span class="kw"><a href="../reference/prepare.html">prepare</a></span>(treatplanN, d)
<span class="kw">summary</span>(<span class="kw">lm</span>(y ~<span class="st"> </span>x_badCoderN, <span class="dt">data=</span> treatedD))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x_badCoderN, data = treatedD)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1822 -0.7879 -0.0334  0.6864  2.8753 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)    574.7      520.1   1.105    0.272
## x_badCoderN  -2936.2     2658.2  -1.105    0.272
## 
## Residual standard error: 1.114 on 98 degrees of freedom
## Multiple R-squared:  0.0123, Adjusted R-squared:  0.002218 
## F-statistic:  1.22 on 1 and 98 DF,  p-value: 0.272</code></pre>
<p><code>vtreat</code> correctly works on this example in the cross-frame pattern, and rejects the bad custom variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cfe &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mkCrossFrameNExperiment.html">mkCrossFrameNExperiment</a></span>(d, 
                               <span class="dt">varlist =</span> <span class="kw">c</span>(<span class="st">'x'</span>),
                               <span class="dt">outcomename =</span> <span class="st">'y'</span>,
                               <span class="dt">codeRestriction =</span> <span class="st">'badCoderN'</span>,
                               <span class="dt">customCoders =</span> customCoders)
<span class="kw">t</span>(cfe$treatments$scoreFrame)</code></pre></div>
<pre><code>##                   1            
## varName           "x_badCoderN"
## varMoves          "TRUE"       
## rsq               "0.0010101"  
## sig               "0.7535938"  
## needsSplit        "TRUE"       
## extraModelDegrees "1"          
## origName          "x"          
## code              "badCoderN"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(y ~<span class="st"> </span>x_badCoderN, <span class="dt">data=</span> cfe$crossFrame))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x_badCoderN, data = cfe$crossFrame)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0275 -0.7469 -0.0020  0.6375  2.9630 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.5804     1.1214   0.518    0.606
## x_badCoderN  -1.9741     5.7165  -0.345    0.731
## 
## Residual standard error: 1.121 on 98 degrees of freedom
## Multiple R-squared:  0.001215,   Adjusted R-squared:  -0.008976 
## F-statistic: 0.1193 on 1 and 98 DF,  p-value: 0.7306</code></pre>
<p>However, specifying <code>oneWayHoldout</code> as the cross-validation technique introduces sampling variation that is correlated with the outcome. This causes the value in the synthetic cross-frame (used both for calculating variable significances and returned to the use for further training) to have a spurious correlation with the outcome. The completely deterministic structure of leave-one-out holdout itself represents an information leak that poisons results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cfeBad &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mkCrossFrameNExperiment.html">mkCrossFrameNExperiment</a></span>(d, 
                                  <span class="dt">varlist =</span> <span class="kw">c</span>(<span class="st">'x'</span>),
                                  <span class="dt">outcomename =</span> <span class="st">'y'</span>,
                                  <span class="dt">codeRestriction =</span> <span class="st">'badCoderN'</span>,
                                  <span class="dt">customCoders =</span> customCoders,
                                  <span class="dt">splitFunction =</span> oneWayHoldout)
<span class="kw">t</span>(cfeBad$treatments$scoreFrame)</code></pre></div>
<pre><code>##                   1             
## varName           "x_badCoderN" 
## varMoves          "TRUE"        
## rsq               "0.9999893"   
## sig               "2.40545e-245"
## needsSplit        "TRUE"        
## extraModelDegrees "1"           
## origName          "x"           
## code              "badCoderN"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(y ~<span class="st"> </span>x_badCoderN, <span class="dt">data=</span> cfeBad$crossFrame))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x_badCoderN, data = cfeBad$crossFrame)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -0.0113462 -0.0027342  0.0002138  0.0023608  0.0077726 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  19.556211   0.006687    2925   &lt;2e-16 ***
## x_badCoderN -98.988384   0.034131   -2900   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.003827 on 98 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 8.411e+06 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">treatedDbad &lt;-<span class="st"> </span><span class="kw"><a href="../reference/prepare.html">prepare</a></span>(cfeBad$treatments, d)
<span class="kw">summary</span>(<span class="kw">lm</span>(y ~<span class="st"> </span>x_badCoderN, <span class="dt">data=</span> treatedDbad))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x_badCoderN, data = treatedDbad)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1822 -0.7879 -0.0334  0.6864  2.8753 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)     2499       2262   1.105    0.272
## x_badCoderN   -12780      11570  -1.105    0.272
## 
## Residual standard error: 1.114 on 98 degrees of freedom
## Multiple R-squared:  0.0123, Adjusted R-squared:  0.002218 
## F-statistic:  1.22 on 1 and 98 DF,  p-value: 0.272</code></pre>
<p>Notice the following non-deterministic (replacing copying data with sampling with replacement) variation of one-way-hold out does not have the same problem if we have enough data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">oneWayHoldoutR &lt;-<span class="st"> </span>function(nRows,nSplits,dframe,y) {
  if(nRows&lt;=<span class="dv">1</span>) {
    <span class="kw">return</span>(<span class="ot">NULL</span>)
  }
  fullSeq &lt;-<span class="st"> </span><span class="kw">seq_len</span>(nRows)
  evalSets &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="kw">as.list</span>(fullSeq),
                     function(appi) { 
                       ui &lt;-<span class="st"> </span><span class="kw">setdiff</span>(fullSeq,appi)
                       <span class="kw">list</span>(<span class="dt">train=</span><span class="kw">sample</span>(ui, <span class="kw">floor</span>(<span class="kw">length</span>(ui)/<span class="dv">2</span>), <span class="dt">replace=</span><span class="ot">TRUE</span>), <span class="dt">app=</span>appi)
                     })
  <span class="kw">attr</span>(evalSets,<span class="st">'splitmethod'</span>) &lt;-<span class="st"> 'oneway'</span>
  evalSets
}

cfeFX &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mkCrossFrameNExperiment.html">mkCrossFrameNExperiment</a></span>(d, 
                                  <span class="dt">varlist =</span> <span class="kw">c</span>(<span class="st">'x'</span>),
                                  <span class="dt">outcomename =</span> <span class="st">'y'</span>,
                                  <span class="dt">codeRestriction =</span> <span class="st">'badCoderN'</span>,
                                  <span class="dt">customCoders =</span> customCoders,
                                  <span class="dt">splitFunction =</span> oneWayHoldoutR)
<span class="kw">t</span>(cfeFX$treatments$scoreFrame)</code></pre></div>
<pre><code>##                   1            
## varName           "x_badCoderN"
## varMoves          "TRUE"       
## rsq               "0.00183226" 
## sig               "0.6723965"  
## needsSplit        "TRUE"       
## extraModelDegrees "1"          
## origName          "x"          
## code              "badCoderN"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(y ~<span class="st"> </span>x_badCoderN, <span class="dt">data=</span> cfeFX$crossFrame))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x_badCoderN, data = cfeFX$crossFrame)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.04824 -0.63572 -0.02567  0.69015  3.06855 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   0.3124     0.1784   1.751    0.083 .
## x_badCoderN  -0.6347     0.7524  -0.844    0.401  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.117 on 98 degrees of freedom
## Multiple R-squared:  0.007209,   Adjusted R-squared:  -0.002921 
## F-statistic: 0.7116 on 1 and 98 DF,  p-value: 0.401</code></pre>
<p>What happened is:</p>
<ul>
<li>The deterministic structure of leave-one-out cross validation introduces an information leak that copies a transform of the value of <code>y</code> into the bad coder. Essentially the leave-one-out cross validation is consuming a number of degrees of freedom equal to the number of different data sets its presents (one per data row).</li>
<li>The bad coder being a near constant means this leak is nearly the entirety of the bad coder signal.</li>
<li>On any data set other than the one-way-holdout cross-validation frame the bad coder is in fact a noisy constant (and not useful). The the bad coder is pure over-fit and any model that uses it is at risk of over-fit.</li>
</ul>
<p>In the failing example the value returned data-row <code>k</code> is essentially the mean of all rows except the <code>k</code>-th row due to the leave-one-out holdout. Call this estimate <code>e(k)</code> (the estimate assigned to the <code>k</code>-th row).</p>
<p>The coding-estimate for the <code>k</code>-th row is essentially <code>(1/(n-1)) sum(i = 1, ...,n; i not k) y(i)</code> (where <code>n</code> is the number of training data rows, and <code>y(i)</code> is the <code>i</code>-th dependent value). That is the coder builds its coding of the <code>k</code>-th row by averaging all of the training dependent values it is allowed to see under the leave-1-out cross validation procedure. In an isolated sense its calculation of the <code>k</code>-th row is independent of <code>y(k)</code> as that value was not shown to the procedure at that time.</p>
<p>However by algebra we have this estimate <code>e(k)</code> is also equal to <code>(n/(n-1)) mean(y) - y(k)/(n-1)</code>. So a step in the procedure that also knows <code>mean(y)</code> (such as say the <code>lm()</code> linear regression models shown above, and the variable significance procedures used to build the <code>scoreFrame</code>s) we know that <code>y(k) = sum(y) - (n-1) e(k)</code>. Or in vector form (<code>y</code> and <code>e</code> being the vectors, all other terms scalars): <code>y = sum(y) - (n-1) e</code>. Jointly for all rows the dependent variable <code>y</code> is a simple linear function of the estimates <code>e</code>, even though each estimate <code>e(k)</code> with no knowledge of the dependent value <code>y(k)</code> in the same row.</p>
<p>Or: to an observer that knows <code>n</code> and <code>mean(y)</code> (and hence <code>sum(y)</code>) <code>e(k)</code> completely determines <code>y(k)</code> even though it was constructed without knowledge of <code>y(k)</code>.</p>
<p>This failing is because the common cross validation procedures are not <a href="http://www.win-vector.com/blog/2017/01/a-theory-of-nested-cross-simulation/">fully nested simulation</a> in the sense that rows were not excluded from out final calculation (the estimation of significance, or final linear model). I did not correctly make the distinction when laying out the theory of notation in the previous article, but the idea is to maintain full exchangeability every step of the simulation must systematically exclude sets of rows: especially the last step if it is performing join over all rows calculations.</p>
<p><em>Fully</em> nested cross-simulation (where even the last step is under the cross-control and enumerating excluded sets of training rows) is likely too cumbersome (requiring more code coordination) and expensive (upping the size of the sets of rows we have to exclude) to force on implementers who are also unlikely to see any benefit in non-degenerate cases. The partially nested cross-simulation used in <code>vtreat</code> is likely a good practical compromise (though we may explore full-nesting for the score frame estimates, as that is a step completely under <code>vtreat</code> control).</p>
<p>The current <code>vtreat</code> procedures are very strong and fully up to the case of assisting in construction of best possible machine learning models. However in certain degenerate cases (near-constant encoding combined completely deterministic cross-validation; neither of which is a default behavior of <code>vtreat</code>) the cross validation system itself can introduce an information leak that promote over-fit.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by John Mount, Nina Zumel.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>

---
title: "vtreat on Spark"
output: github_document
---

```{r setup}
library("vtreat")
packageVersion("vtreat")
library("rquery")
packageVersion("rquery")
packageVersion("cdata")
packageVersion("sparklyr")


db <- sparklyr::spark_connect(version='2.2.0', 
                              master = "local")
db_opts <- rq_connection_tests(db)
options(db_opts)
```

```{r data, include = FALSE}
dir = '~/Documents/work/PracticalDataScienceWithR/zmPDSwR/KDD2009/' 

d = read.table(paste(dir,'orange_small_train.data.gz',sep=''),
               header=TRUE, sep='\t', na.strings=c('NA',''), 
               stringsAsFactors=FALSE)
churn = read.table(paste(dir,'orange_small_train_churn.labels.txt', sep=''),
                    header=FALSE, sep='\t')
d$churn = churn$V1
rq_copy_to(db, "kdd2009", d,
           overwrite = TRUE,
           temporary = TRUE)
rm(list = c("dir", "d", "churn"))
```

```{r start}
tmp_name_gen <- wrapr::mk_tmp_name_source("kddvtreat")

d <- db_td(db, "kdd2009") %.>%
  extend_nse(., sample_col = random())

cat(format(d))
cat(to_sql(d, db))

d <- materialize(db, d, table_name = tmp_name_gen())

y_name <- "churn"
vars <- setdiff(column_names(d), c(y_name, "sample_col"))

d_train <- d %.>%
  select_rows_nse(., sample_col <= 0.5) %.>%
  materialize(db, ., table_name = tmp_name_gen())

d_test <- d %.>%
  select_rows_nse(., sample_col > 0.9) %.>%
  materialize(db, ., table_name = tmp_name_gen())

d_variable_design <- d %.>%
  select_rows_nse(., (sample_col > 0.5) & (sample_col <= 0.9)) %.>%
  materialize(db, ., table_name = tmp_name_gen())
```

```{r design_var_treatments}
cl = parallel::makeCluster(4)
print(length(vars))
# treat variables in small groups to manage memory
vgroups <- split(vars, ceiling(seq_len(length(vars))/10))
treatment_plans <- lapply(vgroups,
                          function(vi) {
                            di <- d_variable_design %.>%
                              select_columns(., c(y_name, vi)) %.>%
                              execute(db, .)
                            vtreat::designTreatmentsC(di, vi, y_name, 1, 
                                                      parallelCluster = cl,
                                                      verbose = FALSE)
                          })
n_new <- vapply(treatment_plans,
                function(tpi) {
                  nrow(tpi$scoreFrame)
                }, numeric(1))
n_new <- sum(n_new)
approximate_df <- length(vars) + n_new
theshold <- 1/(1 + approximate_df)
# try to get Bonferroni- corrected valid derived variables.
newvars <- lapply(treatment_plans,
                  function(tpi) {
                    sfi <- tpi$scoreFrame
                    sfi$varName[(sfi$sig < theshold) & 
                                   (sfi$rsq >= 1.0e-3)]
                  })
newvars <- unlist(newvars)
print(length(newvars))
```


```{r treatdata}
rqplan <- as_rquery_plan(treatment_plans, var_restriction = newvars)
# ops <- flatten_fn_list(d_train, rqplan$optree_generators)
# cat(format(ops))
# sql <- to_sql(ops, db)
d_train <- materialize_treated(db, rqplan, d_train, 
                               tmp_name_gen(), 
                               temporary = TRUE, overwrite = TRUE)
length(column_names(d_train))
cdata::qlook(db, d_train$table_name)
```




```{r cleanup, include = FALSE}
parallel::stopCluster(cl)
for(ti in tmp_name_gen(dumpList = TRUE)) {
  rq_remove_table(db = db, table_name = ti)
}
sparklyr::spark_disconnect(db)
```

---
title: "Modeling Pipelines"
output: html_document
---

Reusable modeling pipelines are a practical idea that gets re-developed many times in many contexts.  [`wrapr`](https://github.com/WinVector/wrapr)  supplies a particularly powerful pipeline notation and as of version `1.7.1` pipeline re-use system.  We will demonstrate this with the [`vtreat`](https://github.com/WinVector/vtreat) data preparation system.

```{r setup}
library("wrapr")
library("vtreat")
library("glmnet")
library("WVPlots")

mk_data <- function(nrows, n_var_cols, n_noise_cols) {
  d <- data.frame(y = rnorm(nrows))
  for(i in seq_len(n_var_cols)) {
    vari = paste0("var_", sprintf("%03g", i))
    d[[vari]] <- rnorm(nrows)
    d$y <- d$y + (2/n_var_cols)*d[[vari]]
    d[[vari]][d[[vari]]>abs(2*rnorm(nrows))] <- NA
    d[[vari]] <- rlnorm(1, meanlog=10, sdlog = 10)*d[[vari]]
  }
   for(i in seq_len(n_noise_cols)) {
    vari = paste0("noise_", sprintf("%03g", i))
    d[[vari]] <- rnorm(nrows)
    d[[vari]][d[[vari]]>abs(2*rnorm(nrows))] <- NA
    d[[vari]] <- rlnorm(1, meanlog=10, sdlog = 10)*d[[vari]]
   }
  d
}

set.seed(2018)
d <- mk_data(10000, 10, 200)
is_train <- runif(nrow(d))<=0.5
dTrain <- d[is_train, , drop = FALSE]
dTest <- d[!is_train, , drop = FALSE]
outcome_name <- "y"
vars <- setdiff(colnames(dTrain), outcome_name)
```

Suppose our analysis plan is the following:

 * Fix missing values with `vtreat`.
 * Scale and center the data.
 * Model `y` as a function of the other columns using `glmnet`.

Now both `vtreat` and `glmnet` can scale, but we are going to keep the scaling
as a seperate step to show how composite data preperation pipelines work.

This can be done as follows.

```{r model1}
# design a treatment plan using cross-validation methods
cp <- vtreat::mkCrossFrameNExperiment(dTrain, vars, outcome_name)

# get the list of new variables
sf <- cp$treatments$scoreFrame
newvars <- sf$varName[sf$sig <= 1/nrow(sf)]
print(newvars)

# learn a centering and scaling of the cross-validated 
# training frame
tfs <- scale(cp$crossFrame[, newvars, drop = FALSE], 
             center = TRUE, scale = TRUE)
centering <- attr(tfs, "scaled:center")
scaling <- attr(tfs, "scaled:scale")

# apply the centering and scaling to the cross-validated 
# training frame
tfs <- scale(cp$crossFrame[, newvars, drop = FALSE],
             center = centering,
             scale = scaling)

model <- cv.glmnet(as.matrix(tfs), 
                   cp$crossFrame[[outcome_name]],
                   alpha = 1,
                   family = "gaussian", 
                   standardize = FALSE)

pipeline <- pipe_list(
  wrap_fname_S3('prepare',
                fn_package = "vtreat",
                arg_name = "dframe", 
                args = list(treatmentplan = cp$treatments,
                            varRestriction = newvars)),
  wrap_fname_S3('subset',
                arg_name = "x",
                args = list(select = newvars)),
  wrap_fname_S3('scale',
                arg_name = "x",
                args = list(center = centering,
                            scale = scaling)),
  wrap_fname_S3("predict.cv.glmnet",
                fn_package = "glmnet",
                arg_name = "newx",
                args = list(object = model,
                            s = "lambda.1se")))
  

#dTrain %.>% pipeline
#dTest %.>% pipeline

dTrain$prediction <- (dTrain %.>% pipeline)[, 1, drop = TRUE]

WVPlots::ScatterHist(dTrain, "prediction", "y", "fit on training data",
                     smoothmethod = "identity",
                     estimate_sig = TRUE,
                     point_alpha = 0.1,
                     contour = TRUE)

dTest$prediction <- (dTest %.>% pipeline)[, 1, drop = TRUE]

WVPlots::ScatterHist(dTest, "prediction", "y", "fit on test",
                     smoothmethod = "identity",
                     estimate_sig = TRUE,
                     point_alpha = 0.1,
                     contour = TRUE)
```


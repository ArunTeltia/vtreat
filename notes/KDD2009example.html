<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># To make the html: echo &quot;library(knitr); knit(&#39;KDD2009example.Rmd&#39;)&quot; | R --vanilla ; pandoc KDD2009example.md -o KDD2009example.html</span>
<span class="co"># Example of working with KDD2009 data (just to show library at work).</span>
<span class="co"># For data and details see: https://github.com/WinVector/zmPDSwR/tree/master/KDD2009</span>
<span class="co"># and Chapter 6 of Practical Data Science with R: http://www.amazon.com/Practical-Data-Science/dp/1617291560</span>
<span class="co"># load the data as in the book</span>
dir &lt;-<span class="st"> &#39;~/Documents/work/DataScienceBook/zmPDSwR/KDD2009/&#39;</span> <span class="co"># change this path to match your directory structure</span>
d &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">paste</span>(dir,<span class="st">&#39;orange_small_train.data.gz&#39;</span>,<span class="dt">sep=</span><span class="st">&#39;&#39;</span>),
                <span class="dt">header=</span>T,<span class="dt">sep=</span><span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>,<span class="dt">na.strings=</span><span class="kw">c</span>(<span class="st">&#39;NA&#39;</span>,<span class="st">&#39;&#39;</span>))
churn &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">paste</span>(dir,<span class="st">&#39;orange_small_train_churn.labels.txt&#39;</span>,<span class="dt">sep=</span><span class="st">&#39;&#39;</span>),
                    <span class="dt">header=</span>F,<span class="dt">sep=</span><span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>)
d$churn &lt;-<span class="st"> </span>churn$V1
appetency &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">paste</span>(dir,<span class="st">&#39;orange_small_train_appetency.labels.txt&#39;</span>,<span class="dt">sep=</span><span class="st">&#39;&#39;</span>),
                        <span class="dt">header=</span>F,<span class="dt">sep=</span><span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>)
d$appetency &lt;-<span class="st"> </span>appetency$V1
upselling &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">paste</span>(dir,<span class="st">&#39;orange_small_train_upselling.labels.txt&#39;</span>,<span class="dt">sep=</span><span class="st">&#39;&#39;</span>),
                        <span class="dt">header=</span>F,<span class="dt">sep=</span><span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>)
d$upselling &lt;-<span class="st"> </span>upselling$V1
<span class="kw">set.seed</span>(<span class="dv">729375</span>)
d$rgroup &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="kw">dim</span>(d)[[<span class="dv">1</span>]])
dTrainPri &lt;-<span class="st"> </span><span class="kw">subset</span>(d,rgroup&lt;=<span class="fl">0.8</span>)
dTrainCal &lt;-<span class="st"> </span><span class="kw">subset</span>(d,rgroup&gt;<span class="fl">0.8</span> &amp;<span class="st"> </span>rgroup&lt;=<span class="fl">0.9</span>)
dTest &lt;-<span class="st"> </span><span class="kw">subset</span>(d,rgroup&gt;<span class="fl">0.9</span>)
<span class="kw">rm</span>(<span class="dt">list=</span><span class="kw">c</span>(<span class="st">&#39;d&#39;</span>,<span class="st">&#39;churn&#39;</span>,<span class="st">&#39;appetency&#39;</span>,<span class="st">&#39;upselling&#39;</span>,<span class="st">&#39;dir&#39;</span>))
outcomes &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;churn&#39;</span>,<span class="st">&#39;appetency&#39;</span>,<span class="st">&#39;upselling&#39;</span>)
vars &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(dTrainPri),
                <span class="kw">c</span>(outcomes,<span class="st">&#39;rgroup&#39;</span>))
yName &lt;-<span class="st"> &#39;churn&#39;</span>
yTarget &lt;-<span class="st"> </span><span class="dv">1</span>
yCond &lt;-<span class="st"> </span><span class="kw">paste</span>(yName,yTarget,<span class="dt">sep=</span><span class="st">&#39;==&#39;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#load some libraries</span>
<span class="kw">library</span>(<span class="st">&#39;vtreat&#39;</span>)  <span class="co"># This library isn&#39;t public yet, intall instructions: http://www.win-vector.com/blog/2014/08/vtreat-designing-a-package-for-variable-treatment/</span>

<span class="co"># try the automatic variable treatment</span>
<span class="kw">set.seed</span>(<span class="dv">239525</span>)
treatments &lt;-<span class="st"> </span><span class="kw">designTreatmentsC</span>(dTrainPri,
    vars,yName,yTarget,<span class="dt">smFactor=</span><span class="fl">1.0</span>,<span class="dt">minFraction=</span><span class="fl">2.0</span>,<span class="dt">maxMissing=</span>-<span class="fl">1.0</span>)
<span class="kw">save</span>(<span class="dt">file=</span><span class="st">&#39;kdd2009ex.Rdata&#39;</span>,<span class="dt">list=</span><span class="kw">ls</span>())</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#load(&#39;kdd2009ex.Rdata&#39;) # how we would load the data by hand</span>
<span class="co">#load/re-load some libraries</span>
<span class="kw">library</span>(<span class="st">&#39;ggplot2&#39;</span>)
<span class="kw">library</span>(<span class="st">&#39;ROCR&#39;</span>)</code></pre>
<pre><code>## Loading required package: gplots
## KernSmooth 2.23 loaded
## Copyright M. P. Wand 1997-2009
## 
## Attaching package: &#39;gplots&#39;
## 
## The following object is masked from &#39;package:stats&#39;:
## 
##     lowess</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&#39;vtreat&#39;</span>)
<span class="kw">library</span>(<span class="st">&#39;randomForest&#39;</span>)</code></pre>
<pre><code>## randomForest 4.6-7
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&#39;class&#39;</span>)



<span class="co"># select variables that look good in calibration</span>
pruneLevel &lt;-<span class="st"> </span><span class="fl">0.99999</span> <span class="co"># noisy weak variables, so not leaning on PRESS statistic</span>
treatedTrain &lt;-<span class="st"> </span><span class="kw">prepare</span>(treatments,dTrainPri,
                        <span class="dt">pruneLevel=</span>pruneLevel,<span class="dt">scale=</span><span class="ot">TRUE</span>)
treatedCal &lt;-<span class="st"> </span><span class="kw">prepare</span>(treatments,dTrainCal,
                        <span class="dt">pruneLevel=</span>pruneLevel,<span class="dt">scale=</span><span class="ot">TRUE</span>)
treatedTest &lt;-<span class="st"> </span><span class="kw">prepare</span>(treatments,dTest,
                       <span class="dt">pruneLevel=</span>pruneLevel,<span class="dt">scale=</span><span class="ot">TRUE</span>)
scoreVarCal &lt;-<span class="st"> </span>function(vname,trainFrame,calFrame) {
  mv &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">paste</span>(yCond,vname,<span class="dt">sep=</span><span class="st">&#39; ~ &#39;</span>),<span class="dt">data=</span>trainFrame,<span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">&#39;logit&#39;</span>))
  sv &lt;-<span class="st"> </span><span class="kw">predict</span>(mv,<span class="dt">newdata=</span>calFrame,<span class="dt">type=</span><span class="st">&#39;response&#39;</span>)
  ncal &lt;-<span class="st"> </span><span class="kw">length</span>(calFrame[,yName])
  sc &lt;-<span class="st"> </span><span class="kw">sum</span>(calFrame[,yName]==yTarget)/ncal
  (<span class="kw">sum</span>(<span class="kw">ifelse</span>(calFrame[,yName]==yTarget,<span class="kw">log</span>(sv),<span class="kw">log</span>(<span class="dv">1</span>-sv))) -<span class="st"> </span><span class="kw">sum</span>(<span class="kw">ifelse</span>(calFrame[,yName]==yTarget,<span class="kw">log</span>(sc),<span class="kw">log</span>(<span class="dv">1</span>-sc))))/ncal
}
m1vars &lt;-<span class="st"> </span><span class="kw">intersect</span>(treatments$vars,<span class="kw">colnames</span>(treatedTrain))
varValues &lt;-<span class="st"> </span><span class="kw">sapply</span>(m1vars,function(v) <span class="kw">scoreVarCal</span>(v,treatedTrain,treatedCal)) <span class="co"># weak noisy variables, so score on calibration set</span></code></pre>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">table</span>(<span class="dt">PRESSgood=</span>treatments$varScores[m1vars]&lt;<span class="dv">1</span>,<span class="dt">CALgood=</span>varValues&gt;<span class="dv">0</span>))</code></pre>
<pre><code>##          CALgood
## PRESSgood FALSE TRUE
##      TRUE    66  143</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">mvars &lt;-<span class="st"> </span><span class="kw">names</span>(varValues)[varValues&gt;<span class="fl">1.0e-5</span>]


<span class="co"># Add some principal components as new synthetic variables (better would be something like partial least squares </span>
<span class="co"># as we are working towards inverse-regressio style effects).  </span>
<span class="co"># See http://www.win-vector.com/blog/2014/06/skimming-statistics-papers-for-the-ideas-instead-of-the-complete-procedures/ )</span>
pcomp &lt;-<span class="st"> </span><span class="kw">prcomp</span>(treatedTrain[,mvars])
goodP &lt;-<span class="st"> </span>pcomp$sdev&gt;=<span class="fl">1.0e-3</span>
projection &lt;-<span class="st"> </span>pcomp$rotation[,goodP]
treatedTrainP &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">as.matrix</span>(treatedTrain[,mvars]) %*%<span class="st"> </span>projection)
pvars1 &lt;-<span class="st"> </span><span class="kw">colnames</span>(treatedTrainP)
treatedTrainP &lt;-<span class="st"> </span><span class="kw">cbind</span>(treatedTrainP,treatedTrain)
treatedCalP &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">as.matrix</span>(treatedCal[,mvars]) %*%<span class="st"> </span>projection)
treatedCalP &lt;-<span class="st"> </span><span class="kw">cbind</span>(treatedCalP,treatedCal)
treatedTestP &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">as.matrix</span>(treatedTest[,mvars]) %*%<span class="st"> </span>projection)
treatedTestP &lt;-<span class="st"> </span><span class="kw">cbind</span>(treatedTestP,treatedTest)
pvarValues &lt;-<span class="st"> </span><span class="kw">sapply</span>(pvars1,function(v) <span class="kw">scoreVarCal</span>(v,treatedTrainP,treatedCalP)) <span class="co"># weak noisy variables, so score on calibration set</span>
pvars &lt;-<span class="st"> </span><span class="kw">names</span>(pvarValues)[pvarValues&gt;<span class="fl">1.0e-5</span>]


uvars &lt;-<span class="st"> </span><span class="kw">c</span>(mvars,pvars)


for (varset in <span class="kw">list</span>(mvars,pvars,uvars)) {
   <span class="kw">print</span>(<span class="st">&#39;----------&#39;</span>)
   <span class="kw">print</span>(varset)
   
   <span class="kw">print</span>(<span class="st">&#39;&#39;</span>)
   <span class="kw">print</span>(<span class="st">&#39;glm&#39;</span>)
   <span class="co"># simple glm model (just to show things work)</span>
   formulaP &lt;-<span class="st"> </span><span class="kw">paste</span>(yCond,<span class="kw">paste</span>(varset,<span class="dt">collapse=</span><span class="st">&#39; + &#39;</span>),<span class="dt">sep=</span><span class="st">&#39; ~ &#39;</span>)
   modelP &lt;-<span class="st"> </span><span class="kw">glm</span>(formulaP,<span class="dt">data=</span>treatedTrainP,<span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">&#39;logit&#39;</span>))
   treatedTestP$glmPred &lt;-<span class="st"> </span><span class="kw">predict</span>(modelP,<span class="dt">newdata=</span>treatedTestP,<span class="dt">type=</span><span class="st">&#39;response&#39;</span>)
   <span class="kw">print</span>(<span class="kw">ggplot</span>(<span class="dt">data=</span>treatedTestP) +
<span class="st">      </span><span class="kw">geom_density</span>(<span class="kw">aes_string</span>(<span class="dt">x=</span><span class="st">&#39;glmPred&#39;</span>,<span class="dt">color=</span><span class="kw">paste</span>(<span class="st">&#39;as.factor(&#39;</span>,yName,<span class="st">&#39;)&#39;</span>))))
   <span class="co"># compute AUC aas in chapter 5 of Practical Data Science with R</span>
   ROCR_glmPred &lt;-<span class="st"> </span><span class="kw">prediction</span>(treatedTestP$glmPred,treatedTest[,yName]==yTarget)
   <span class="co">#plot(performance(ROCR_glmPred,&quot;tpr&quot;,&quot;fpr&quot;))</span>
   glmPredAUC &lt;-<span class="st"> </span><span class="kw">attributes</span>(<span class="kw">performance</span>(ROCR_glmPred,<span class="st">&#39;auc&#39;</span>))$y.values[[<span class="dv">1</span>]]
   <span class="kw">print</span>(glmPredAUC)
   <span class="kw">print</span>(<span class="st">&#39;&#39;</span>)

   <span class="kw">print</span>(<span class="st">&#39;&#39;</span>)
   <span class="kw">print</span>(<span class="st">&#39;randomForest&#39;</span>)
   <span class="co"># random forest model, see chapter 9 of Practical Data Science with R</span>
   modelF &lt;-<span class="st"> </span><span class="kw">randomForest</span>(<span class="dt">x=</span>treatedTrainP[,varset],
      <span class="dt">y=</span><span class="kw">as.factor</span>(treatedTrainP[,yName]==yTarget),
      <span class="dt">ntree=</span><span class="dv">300</span>)
   treatedTestP$rfPred &lt;-<span class="st"> </span><span class="kw">predict</span>(modelF,<span class="dt">newdata=</span>treatedTestP[,varset],<span class="dt">type=</span><span class="st">&#39;prob&#39;</span>)[,<span class="st">&#39;TRUE&#39;</span>]
   <span class="kw">print</span>(<span class="kw">ggplot</span>(<span class="dt">data=</span>treatedTestP) +
<span class="st">      </span><span class="kw">geom_density</span>(<span class="kw">aes_string</span>(<span class="dt">x=</span><span class="st">&#39;rfPred&#39;</span>,<span class="dt">color=</span><span class="kw">paste</span>(<span class="st">&#39;as.factor(&#39;</span>,yName,<span class="st">&#39;)&#39;</span>))))
   ROCR_rfPred &lt;-<span class="st"> </span><span class="kw">prediction</span>(treatedTestP$rfPred,treatedTest[,yName]==yTarget)
   <span class="co">#plot(performance(ROCR_rfPred,&quot;tpr&quot;,&quot;fpr&quot;))</span>
   rfPredAUC &lt;-<span class="st"> </span><span class="kw">attributes</span>(<span class="kw">performance</span>(ROCR_rfPred,<span class="st">&#39;auc&#39;</span>))$y.values[[<span class="dv">1</span>]]
   <span class="kw">print</span>(rfPredAUC)
   <span class="kw">print</span>(<span class="st">&#39;&#39;</span>)

   <span class="kw">print</span>(<span class="st">&#39;&#39;</span>)
   <span class="kw">print</span>(<span class="st">&#39;knn&#39;</span>)
   <span class="co"># knn model, see chapter 6 of Practical Data Science with R</span>
   knnPred &lt;-<span class="st"> </span>function(trainF,trainY,nK,testF) {
       knnDecision &lt;-<span class="st"> </span><span class="kw">knn</span>(trainF,testF,trainY,<span class="dt">k=</span>nK,<span class="dt">prob=</span>T)
       <span class="kw">ifelse</span>(knnDecision==<span class="ot">TRUE</span>,
          <span class="kw">attributes</span>(knnDecision)$prob,
          <span class="dv">1</span>-(<span class="kw">attributes</span>(knnDecision)$prob))
   }
   treatedTestP$knnPred &lt;-<span class="st"> </span><span class="kw">knnPred</span>(treatedTrainP[,varset],treatedTrainP[,yName],
                                   <span class="dv">200</span>,
                                   treatedTestP[,varset])
   <span class="kw">print</span>(<span class="kw">ggplot</span>(<span class="dt">data=</span>treatedTestP) +
<span class="st">      </span><span class="kw">geom_density</span>(<span class="kw">aes_string</span>(<span class="dt">x=</span><span class="st">&#39;knnPred&#39;</span>,<span class="dt">color=</span><span class="kw">paste</span>(<span class="st">&#39;as.factor(&#39;</span>,yName,<span class="st">&#39;)&#39;</span>))))
   ROCR_knnPred &lt;-<span class="st"> </span><span class="kw">prediction</span>(treatedTestP$knnPred,treatedTest[,yName]==yTarget)
   <span class="co">#plot(performance(ROCR_knnPred,&quot;tpr&quot;,&quot;fpr&quot;))</span>
   knnPredAUC &lt;-<span class="st"> </span><span class="kw">attributes</span>(<span class="kw">performance</span>(ROCR_knnPred,<span class="st">&#39;auc&#39;</span>))$y.values[[<span class="dv">1</span>]]
   <span class="kw">print</span>(knnPredAUC)
   <span class="kw">print</span>(<span class="st">&#39;&#39;</span>)
}</code></pre>
<pre><code>## [1] &quot;----------&quot;
##   [1] &quot;Var2_isBAD&quot;   &quot;Var3_isBAD&quot;   &quot;Var4_isBAD&quot;   &quot;Var6_clean&quot;  
##   [5] &quot;Var6_isBAD&quot;   &quot;Var7_clean&quot;   &quot;Var7_isBAD&quot;   &quot;Var11_isBAD&quot; 
##   [9] &quot;Var13_clean&quot;  &quot;Var13_isBAD&quot;  &quot;Var14_isBAD&quot;  &quot;Var17_isBAD&quot; 
##  [13] &quot;Var18_isBAD&quot;  &quot;Var19_isBAD&quot;  &quot;Var21_isBAD&quot;  &quot;Var22_isBAD&quot; 
##  [17] &quot;Var24_clean&quot;  &quot;Var24_isBAD&quot;  &quot;Var25_clean&quot;  &quot;Var25_isBAD&quot; 
##  [21] &quot;Var28_clean&quot;  &quot;Var28_isBAD&quot;  &quot;Var34_isBAD&quot;  &quot;Var35_isBAD&quot; 
##  [25] &quot;Var36_isBAD&quot;  &quot;Var37_isBAD&quot;  &quot;Var38_isBAD&quot;  &quot;Var40_isBAD&quot; 
##  [29] &quot;Var43_isBAD&quot;  &quot;Var44_isBAD&quot;  &quot;Var46_isBAD&quot;  &quot;Var49_isBAD&quot; 
##  [33] &quot;Var51_isBAD&quot;  &quot;Var54_isBAD&quot;  &quot;Var56_isBAD&quot;  &quot;Var59_isBAD&quot; 
##  [37] &quot;Var65_clean&quot;  &quot;Var65_isBAD&quot;  &quot;Var68_isBAD&quot;  &quot;Var72_clean&quot; 
##  [41] &quot;Var73_clean&quot;  &quot;Var74_clean&quot;  &quot;Var74_isBAD&quot;  &quot;Var75_isBAD&quot; 
##  [45] &quot;Var76_isBAD&quot;  &quot;Var78_isBAD&quot;  &quot;Var81_clean&quot;  &quot;Var81_isBAD&quot; 
##  [49] &quot;Var82_isBAD&quot;  &quot;Var83_isBAD&quot;  &quot;Var84_isBAD&quot;  &quot;Var85_clean&quot; 
##  [53] &quot;Var85_isBAD&quot;  &quot;Var88_isBAD&quot;  &quot;Var89_isBAD&quot;  &quot;Var95_isBAD&quot; 
##  [57] &quot;Var96_isBAD&quot;  &quot;Var99_isBAD&quot;  &quot;Var101_isBAD&quot; &quot;Var102_isBAD&quot;
##  [61] &quot;Var104_isBAD&quot; &quot;Var105_isBAD&quot; &quot;Var106_isBAD&quot; &quot;Var109_isBAD&quot;
##  [65] &quot;Var110_clean&quot; &quot;Var112_isBAD&quot; &quot;Var113_clean&quot; &quot;Var114_isBAD&quot;
##  [69] &quot;Var115_isBAD&quot; &quot;Var117_isBAD&quot; &quot;Var119_isBAD&quot; &quot;Var122_isBAD&quot;
##  [73] &quot;Var123_isBAD&quot; &quot;Var124_isBAD&quot; &quot;Var125_clean&quot; &quot;Var125_isBAD&quot;
##  [77] &quot;Var126_clean&quot; &quot;Var126_isBAD&quot; &quot;Var127_isBAD&quot; &quot;Var128_isBAD&quot;
##  [81] &quot;Var130_isBAD&quot; &quot;Var132_isBAD&quot; &quot;Var133_isBAD&quot; &quot;Var134_isBAD&quot;
##  [85] &quot;Var135_isBAD&quot; &quot;Var138_isBAD&quot; &quot;Var139_clean&quot; &quot;Var140_isBAD&quot;
##  [89] &quot;Var143_isBAD&quot; &quot;Var144_clean&quot; &quot;Var144_isBAD&quot; &quot;Var145_isBAD&quot;
##  [93] &quot;Var149_clean&quot; &quot;Var149_isBAD&quot; &quot;Var150_isBAD&quot; &quot;Var152_isBAD&quot;
##  [97] &quot;Var153_isBAD&quot; &quot;Var155_isBAD&quot; &quot;Var158_isBAD&quot; &quot;Var159_isBAD&quot;
## [101] &quot;Var160_clean&quot; &quot;Var160_isBAD&quot; &quot;Var161_isBAD&quot; &quot;Var162_isBAD&quot;
## [105] &quot;Var163_isBAD&quot; &quot;Var164_isBAD&quot; &quot;Var165_isBAD&quot; &quot;Var168_clean&quot;
## [109] &quot;Var170_isBAD&quot; &quot;Var171_isBAD&quot; &quot;Var173_isBAD&quot; &quot;Var174_isBAD&quot;
## [113] &quot;Var176_isBAD&quot; &quot;Var177_isBAD&quot; &quot;Var178_isBAD&quot; &quot;Var179_isBAD&quot;
## [117] &quot;Var181_isBAD&quot; &quot;Var182_isBAD&quot; &quot;Var183_isBAD&quot; &quot;Var184_isBAD&quot;
## [121] &quot;Var188_clean&quot; &quot;Var188_isBAD&quot; &quot;Var189_clean&quot; &quot;Var191_catN&quot; 
## [125] &quot;Var193_catN&quot;  &quot;Var197_catN&quot;  &quot;Var203_catN&quot;  &quot;Var205_catN&quot; 
## [129] &quot;Var206_catN&quot;  &quot;Var207_catN&quot;  &quot;Var208_catN&quot;  &quot;Var210_catN&quot; 
## [133] &quot;Var211_catN&quot;  &quot;Var218_catN&quot;  &quot;Var219_catN&quot;  &quot;Var221_catN&quot; 
## [137] &quot;Var223_catN&quot;  &quot;Var224_catN&quot;  &quot;Var225_catN&quot;  &quot;Var226_catN&quot; 
## [141] &quot;Var227_catN&quot;  &quot;Var228_catN&quot;  &quot;Var229_catN&quot; 
## [1] &quot;&quot;
## [1] &quot;glm&quot;</code></pre>
<pre><code>## Warning: prediction from a rank-deficient fit may be misleading</code></pre>
<div class="figure">
<img src="figure/kddexanalyze1.png" alt="plot of chunk kddexanalyze" /><p class="caption">plot of chunk kddexanalyze</p>
</div>
<pre><code>## [1] 0.6971
## [1] &quot;&quot;
## [1] &quot;&quot;
## [1] &quot;randomForest&quot;</code></pre>
<div class="figure">
<img src="figure/kddexanalyze2.png" alt="plot of chunk kddexanalyze" /><p class="caption">plot of chunk kddexanalyze</p>
</div>
<pre><code>## [1] 0.6968
## [1] &quot;&quot;
## [1] &quot;&quot;
## [1] &quot;knn&quot;</code></pre>
<div class="figure">
<img src="figure/kddexanalyze3.png" alt="plot of chunk kddexanalyze" /><p class="caption">plot of chunk kddexanalyze</p>
</div>
<pre><code>## [1] 0.6893
## [1] &quot;&quot;
## [1] &quot;----------&quot;
##  [1] &quot;PC1&quot;  &quot;PC2&quot;  &quot;PC3&quot;  &quot;PC4&quot;  &quot;PC5&quot;  &quot;PC6&quot;  &quot;PC8&quot;  &quot;PC13&quot; &quot;PC15&quot; &quot;PC16&quot;
## [11] &quot;PC17&quot; &quot;PC19&quot; &quot;PC22&quot; &quot;PC23&quot; &quot;PC24&quot; &quot;PC26&quot; &quot;PC29&quot; &quot;PC30&quot; &quot;PC31&quot; &quot;PC34&quot;
## [21] &quot;PC36&quot; &quot;PC37&quot; &quot;PC42&quot; &quot;PC44&quot;
## [1] &quot;&quot;
## [1] &quot;glm&quot;</code></pre>
<div class="figure">
<img src="figure/kddexanalyze4.png" alt="plot of chunk kddexanalyze" /><p class="caption">plot of chunk kddexanalyze</p>
</div>
<pre><code>## [1] 0.692
## [1] &quot;&quot;
## [1] &quot;&quot;
## [1] &quot;randomForest&quot;</code></pre>
<div class="figure">
<img src="figure/kddexanalyze5.png" alt="plot of chunk kddexanalyze" /><p class="caption">plot of chunk kddexanalyze</p>
</div>
<pre><code>## [1] 0.6758
## [1] &quot;&quot;
## [1] &quot;&quot;
## [1] &quot;knn&quot;</code></pre>
<pre><code>## [1] 0.6945
## [1] &quot;&quot;
## [1] &quot;----------&quot;
##   [1] &quot;Var2_isBAD&quot;   &quot;Var3_isBAD&quot;   &quot;Var4_isBAD&quot;   &quot;Var6_clean&quot;  
##   [5] &quot;Var6_isBAD&quot;   &quot;Var7_clean&quot;   &quot;Var7_isBAD&quot;   &quot;Var11_isBAD&quot; 
##   [9] &quot;Var13_clean&quot;  &quot;Var13_isBAD&quot;  &quot;Var14_isBAD&quot;  &quot;Var17_isBAD&quot; 
##  [13] &quot;Var18_isBAD&quot;  &quot;Var19_isBAD&quot;  &quot;Var21_isBAD&quot;  &quot;Var22_isBAD&quot; 
##  [17] &quot;Var24_clean&quot;  &quot;Var24_isBAD&quot;  &quot;Var25_clean&quot;  &quot;Var25_isBAD&quot; 
##  [21] &quot;Var28_clean&quot;  &quot;Var28_isBAD&quot;  &quot;Var34_isBAD&quot;  &quot;Var35_isBAD&quot; 
##  [25] &quot;Var36_isBAD&quot;  &quot;Var37_isBAD&quot;  &quot;Var38_isBAD&quot;  &quot;Var40_isBAD&quot; 
##  [29] &quot;Var43_isBAD&quot;  &quot;Var44_isBAD&quot;  &quot;Var46_isBAD&quot;  &quot;Var49_isBAD&quot; 
##  [33] &quot;Var51_isBAD&quot;  &quot;Var54_isBAD&quot;  &quot;Var56_isBAD&quot;  &quot;Var59_isBAD&quot; 
##  [37] &quot;Var65_clean&quot;  &quot;Var65_isBAD&quot;  &quot;Var68_isBAD&quot;  &quot;Var72_clean&quot; 
##  [41] &quot;Var73_clean&quot;  &quot;Var74_clean&quot;  &quot;Var74_isBAD&quot;  &quot;Var75_isBAD&quot; 
##  [45] &quot;Var76_isBAD&quot;  &quot;Var78_isBAD&quot;  &quot;Var81_clean&quot;  &quot;Var81_isBAD&quot; 
##  [49] &quot;Var82_isBAD&quot;  &quot;Var83_isBAD&quot;  &quot;Var84_isBAD&quot;  &quot;Var85_clean&quot; 
##  [53] &quot;Var85_isBAD&quot;  &quot;Var88_isBAD&quot;  &quot;Var89_isBAD&quot;  &quot;Var95_isBAD&quot; 
##  [57] &quot;Var96_isBAD&quot;  &quot;Var99_isBAD&quot;  &quot;Var101_isBAD&quot; &quot;Var102_isBAD&quot;
##  [61] &quot;Var104_isBAD&quot; &quot;Var105_isBAD&quot; &quot;Var106_isBAD&quot; &quot;Var109_isBAD&quot;
##  [65] &quot;Var110_clean&quot; &quot;Var112_isBAD&quot; &quot;Var113_clean&quot; &quot;Var114_isBAD&quot;
##  [69] &quot;Var115_isBAD&quot; &quot;Var117_isBAD&quot; &quot;Var119_isBAD&quot; &quot;Var122_isBAD&quot;
##  [73] &quot;Var123_isBAD&quot; &quot;Var124_isBAD&quot; &quot;Var125_clean&quot; &quot;Var125_isBAD&quot;
##  [77] &quot;Var126_clean&quot; &quot;Var126_isBAD&quot; &quot;Var127_isBAD&quot; &quot;Var128_isBAD&quot;
##  [81] &quot;Var130_isBAD&quot; &quot;Var132_isBAD&quot; &quot;Var133_isBAD&quot; &quot;Var134_isBAD&quot;
##  [85] &quot;Var135_isBAD&quot; &quot;Var138_isBAD&quot; &quot;Var139_clean&quot; &quot;Var140_isBAD&quot;
##  [89] &quot;Var143_isBAD&quot; &quot;Var144_clean&quot; &quot;Var144_isBAD&quot; &quot;Var145_isBAD&quot;
##  [93] &quot;Var149_clean&quot; &quot;Var149_isBAD&quot; &quot;Var150_isBAD&quot; &quot;Var152_isBAD&quot;
##  [97] &quot;Var153_isBAD&quot; &quot;Var155_isBAD&quot; &quot;Var158_isBAD&quot; &quot;Var159_isBAD&quot;
## [101] &quot;Var160_clean&quot; &quot;Var160_isBAD&quot; &quot;Var161_isBAD&quot; &quot;Var162_isBAD&quot;
## [105] &quot;Var163_isBAD&quot; &quot;Var164_isBAD&quot; &quot;Var165_isBAD&quot; &quot;Var168_clean&quot;
## [109] &quot;Var170_isBAD&quot; &quot;Var171_isBAD&quot; &quot;Var173_isBAD&quot; &quot;Var174_isBAD&quot;
## [113] &quot;Var176_isBAD&quot; &quot;Var177_isBAD&quot; &quot;Var178_isBAD&quot; &quot;Var179_isBAD&quot;
## [117] &quot;Var181_isBAD&quot; &quot;Var182_isBAD&quot; &quot;Var183_isBAD&quot; &quot;Var184_isBAD&quot;
## [121] &quot;Var188_clean&quot; &quot;Var188_isBAD&quot; &quot;Var189_clean&quot; &quot;Var191_catN&quot; 
## [125] &quot;Var193_catN&quot;  &quot;Var197_catN&quot;  &quot;Var203_catN&quot;  &quot;Var205_catN&quot; 
## [129] &quot;Var206_catN&quot;  &quot;Var207_catN&quot;  &quot;Var208_catN&quot;  &quot;Var210_catN&quot; 
## [133] &quot;Var211_catN&quot;  &quot;Var218_catN&quot;  &quot;Var219_catN&quot;  &quot;Var221_catN&quot; 
## [137] &quot;Var223_catN&quot;  &quot;Var224_catN&quot;  &quot;Var225_catN&quot;  &quot;Var226_catN&quot; 
## [141] &quot;Var227_catN&quot;  &quot;Var228_catN&quot;  &quot;Var229_catN&quot;  &quot;PC1&quot;         
## [145] &quot;PC2&quot;          &quot;PC3&quot;          &quot;PC4&quot;          &quot;PC5&quot;         
## [149] &quot;PC6&quot;          &quot;PC8&quot;          &quot;PC13&quot;         &quot;PC15&quot;        
## [153] &quot;PC16&quot;         &quot;PC17&quot;         &quot;PC19&quot;         &quot;PC22&quot;        
## [157] &quot;PC23&quot;         &quot;PC24&quot;         &quot;PC26&quot;         &quot;PC29&quot;        
## [161] &quot;PC30&quot;         &quot;PC31&quot;         &quot;PC34&quot;         &quot;PC36&quot;        
## [165] &quot;PC37&quot;         &quot;PC42&quot;         &quot;PC44&quot;        
## [1] &quot;&quot;
## [1] &quot;glm&quot;</code></pre>
<pre><code>## Warning: prediction from a rank-deficient fit may be misleading</code></pre>
<p><img src="figure/kddexanalyze6.png" alt="plot of chunk kddexanalyze" /> <img src="figure/kddexanalyze7.png" alt="plot of chunk kddexanalyze" /></p>
<pre><code>## [1] 0.6971
## [1] &quot;&quot;
## [1] &quot;&quot;
## [1] &quot;randomForest&quot;</code></pre>
<div class="figure">
<img src="figure/kddexanalyze8.png" alt="plot of chunk kddexanalyze" /><p class="caption">plot of chunk kddexanalyze</p>
</div>
<pre><code>## [1] 0.7091
## [1] &quot;&quot;
## [1] &quot;&quot;
## [1] &quot;knn&quot;</code></pre>
<div class="figure">
<img src="figure/kddexanalyze9.png" alt="plot of chunk kddexanalyze" /><p class="caption">plot of chunk kddexanalyze</p>
</div>
<pre><code>## [1] 0.6884
## [1] &quot;&quot;</code></pre>
